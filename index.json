[{"content":" 分析 # 对于p中的字符, 可能出现3种情况: 小写字母, \u0026lsquo;.\u0026rsquo;, \u0026lsquo;*\u0026rsquo;\n由于\u0026quot;*\u0026ldquo;可以匹配0个或者多个字符, 所以对于p中的某一个子串, 在s中可能有多个匹配的子串. 例如\u0026quot;a*b\u0026rdquo; 和 \u0026ldquo;b\u0026rdquo;, \u0026ldquo;ab\u0026rdquo;, \u0026ldquo;aab\u0026quot;都匹配.\n因此, 需要将可能的匹配结果都记录下来. 我们在p中从前往后匹配, 并记录p中的前i个字符在s中的匹配情况.\n我们用二维数组dp来记录匹配情况, dp[i][j]如果是True, 则表示字符p[:i+1]和s[:j+1]匹配.\n为了方便, 我们先记录空字符串和空字符串的匹配情况. 因此dp的第一维长度是len(p)+1 , 第二维长度是len(s)+1. 由于空字符串和空字符串是可以匹配的, 所以dp[0][0]为True.\n由于dp在每一维都增加了1, 因此对于dp[i][j], 与之匹配的字符是p[i-1] 和s[j-1]\nclass Solution: def isMatch(self, s: str, p: str) -\u0026gt; bool: ns = len(s) np = len(p) dp = [[False for _ in range(ns+1)]for _ in range(np+1)] dp[0][0] = True 现在,根据p中出现的字符串来进行相应的判断.\n如果p[i-1] 是\u0026rsquo;.\u0026rsquo;, 那么可以看p[:i-1]和哪些字符串匹配. p[:i-1]的匹配情况保存在dp[i-1]中, 通过遍历发现了所有的匹配字符串, p[i-1]只需与后一个字符匹配即可.\ni = j = 0 for i in range(1, np+1): if p[i-1] == \u0026#34;.\u0026#34;: #能够跟在前一个字符匹配的后面 for j in range(ns): if dp[i-1][j]: dp[i][j+1] = True 如果p[i-1] 是\u0026rsquo;*\u0026rsquo;, 表达的是p[i-2]出现0次或者多次. 因此我们需要看p[:i-3]的匹配情况, 然后让p[i-2]和p[:i-3]匹配成功的字符串后面的字符进行匹配.p[:i-3]的匹配情况保存在dp[i-2]中, 我们对其进行遍历.\ndp[i-2][j]表示p[:i-1]和s[j+1]匹配, 由于\u0026rsquo;*\u0026lsquo;可以匹配0个字符, 因此p[:i+2]也和s[j+1]匹配, 所以dp[i][j] = True.\n如果\u0026rsquo;*\u0026rsquo; 之前出现的是\u0026rsquo;.\u0026rsquo; , 那么就可以匹配任意多个的任意字符\n如果\u0026rsquo;*\u0026lsquo;之前出现的是普通的小写字母, 那就需要这个字符重复的出现\nelif p[i-1] == \u0026#34;*\u0026#34;: for j in range(ns+1): if dp[i-2][j]: dp[i][j] = True # 匹配0个 pre = p[i-2] if pre == \u0026#34;.\u0026#34;: # 如果前一个是\u0026#39;.\u0026#39; 那么就可以匹配任意多的任意字符 for k in range(j+1, ns+1): dp[i][k] = True else: for k in range(j+1, ns+1): if s[k-1] == pre: # *号必须重复之前的字符 dp[i][k] = True else: break 如果p[i-1]是普通的字母, 正常匹配即可\nelse: for j in range(ns): if dp[i-1][j] and p[i-1] == s[j]: dp[i][j+1] = True 由于问题是在问p能否和s匹配, 也就是p[: len(p)+1]和s[:len(s)+1]是否匹配. 因此答案就是dp[len(p)][len(s)]也就是dp[-1][-1].\n","date":"1 September 2023","permalink":"/posts/leetcode/10/","section":"Posts","summary":"分析 # 对于p中的字符, 可能出现3种情况: 小写字母, \u0026lsquo;.","title":"10. 正则表达式匹配"},{"content":"","date":"1 September 2023","permalink":"/series/leetcode/","section":"Series","summary":"","title":"leetcode"},{"content":"","date":"1 September 2023","permalink":"/posts/","section":"Posts","summary":"","title":"Posts"},{"content":"","date":"1 September 2023","permalink":"/","section":"Ryan's blog","summary":"","title":"Ryan's blog"},{"content":"","date":"1 September 2023","permalink":"/series/","section":"Series","summary":"","title":"Series"},{"content":"","date":"1 September 2023","permalink":"/tags/","section":"Tags","summary":"","title":"Tags"},{"content":"","date":"1 September 2023","permalink":"/tags/%E7%BA%BF%E6%80%A7dp/","section":"Tags","summary":"","title":"线性DP"},{"content":"对于一个字符串, 如果它是有效的, 那么就是2种情况:\n最左和最右的字符能凑能一对括号 将字符串从中间某个位置分成2个子串, 且两个子串分别是有效的括号字符串 class Solution: def checkValidString(self, s: str) -\u0026gt; bool: N = len(s) # dp[i][j] 表示 i 到j能否组成合法的字符串 dp = [[False for _ in range(N)] for _ in range(N)] # 仅有一个字符成立的情况 for i in range(N): if s[i] == \u0026#34;*\u0026#34;: dp[i][i] = True # 2个连续字符成立的情况 for i in range(N-1): if (s[i] == \u0026#34;(\u0026#34; or s[i] == \u0026#34;*\u0026#34; )and (s[i+1] == \u0026#34;)\u0026#34; or s[i+1] == \u0026#34;*\u0026#34; ): dp[i][i+1] = True for j in range(N): for i in range(j-2, -1, -1): # 如果两端能组成, 那么就看中间 if (s[i] == \u0026#34;(\u0026#34; or s[i] == \u0026#34;*\u0026#34; )and (s[j] == \u0026#34;)\u0026#34; or s[j] == \u0026#34;*\u0026#34; ): dp[i][j] = dp[i+1][j-1] # 尝试把整个子数组分成两份 k = i while k \u0026lt; j and not dp[i][j]: dp[i][j] = dp[i][k] and dp[k+1][j] k += 1 return dp[0][N-1] ","date":"31 August 2023","permalink":"/posts/leetcode/678/","section":"Posts","summary":"对于一个字符串, 如果它是有效的, 那么就是2种情况:","title":"678.有效的括号字符串"},{"content":"","date":"31 August 2023","permalink":"/tags/%E5%8F%8C%E6%8C%87%E9%92%88/","section":"Tags","summary":"","title":"双指针"},{"content":" 新的指标 # 不同于以往的以最大链路利用(Max Link Utilization, MLU)作为指标的方式. 在FlexDATE中使用了新的指标, 网络扰动(network disturbance). 网络扰动指的是网络发生变化的时候, 切换路径的流量占总流量的比例.\n在FlexDATE中采用MLU 和 diturbance相结合的方式.通过手动设置一个 MLU阈值, 当MLU大于该阈值的时候(网络变拥塞), 强化学习的奖励更加倾向于降低MLU. 当MLU低于阈值的时候, 强化学习的奖励倾向于降低网络扰动.\nFlexDATE设计 # FlexDATE使用GNN + RL + LP的方式来实现功能\nGNN: 通过网络拓扑来提取网络的embedding RL: 包括一个K-net 和 CF-net用来选择关键流(critical flow) LP: 将选择的关键流来构建一个数学模型,通过数学模型来优化降低MLU 模型的输入包括: 新的TM(Traffic Matrix), 旧的TM, 已有的分流比, 上次选择的关键流矩阵.\nTM: 指示两个节点间$s \\to d$的流量 分流比: $s \\to d$多条路径中, 流量在每条路径上的比例. 如红色第二个元素的值分别是0.3, 0.3,0.2,0.2 说明在4条路径中,每条有流量30%, 30%,20%,20% 关键流矩阵: (这里的流指的是$s \\to d$,而不是TCP流的概念)哪些节点之间的流量是关键流,例如图中$0\\to3$, $1\\to2$就是关键流 在GNN中,用临接矩阵(connectivity matrix)来代表网络中的拓扑结构, 通过Attention机制来交换网络特征并提取embedding. 最后让embedding输入到两个网络K-net和CF-net.\nK-net: 用来指示需要选择的关键流的数目. 输出神经元代表每个可以选择的K值的概率.可以看到这里K-net的输出神经元数目代表了选择的最多的关键流数目,是一个预设的参数. CF-net:输出每个流被选择成为关键流的概率.如果拓扑中含有4个节点,那么久包含$4 * (4-1)=12$个输出神经元.然后根据K-net选择的关键流数目选择概率最大的一些流作为关键流 在选择了关键流以后, 对于网络中的所有流使用oblivious routing的方式来计算分流比.在oblivious routing的计算中,并不考虑流的大小(demand), 只根据链权重来计算分流比.因此可以认为oblivious routing的计算的分流比在整个算法运行期间并不会改变.\n而对于关键流则使用类似于SMORE中的分流比计算方式来计算分流比.然后用计算出来的分流比覆盖oblivious routing计算的分流比.\n总结 # 可以总结作者的思路就是通过选择分流比来降低SMORE数学模型的复杂度. 然后将LP优化后的网络的MLU和disturbance来作为强化学习的reward来训练神经网络.\n但是或许可以不通过强化学习的方式来选择关键流. 例如在LP模型中, 用一个binary来代表一个流是不是关键流. 然后设置限制条件:所有binary加起来不能超过K值(关键流的最大数目). 不过这样的话数学模型就需要考虑网络中的所有流,LP模型复杂度会上升.\n","date":"3 December 2022","permalink":"/posts/paperreading/flexdate/","section":"Posts","summary":"新的指标 # 不同于以往的以最大链路利用(Max Link Utilization, MLU)作为指标的方式.","title":"[TON'21] FlexDATE: Flexible and Disturbance-Aware Traffic Engineering With Reinforcement Learning in Software-Defined Networks思路记录"},{"content":"","date":"3 December 2022","permalink":"/series/%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/","section":"Series","summary":"","title":"阅读笔记"},{"content":" 1 背景 # mice流： 通常大小只有几KB的流 elephant流： 数据量很大，可以达到几个GB 1.1 dark routing # 不知道流大小的情况下，也能高效利用网络，并有较小的流完成时间(FCT)\n1.2 传统算法 # 需要持续地检测流，当流发送到一定的数据量以后才会把流归为elephant流。而在这之前，mice 和 elephant流可能会共用已经拥塞的链路。\n在这个例子中，有11条mice 流($f_1 \\cdots f_{11}$)和一条elephant流($f_{12}$)。由于Hedera使用ECMP，流会随机的被分到一条路径上。因此$f_1$和$f_{12}$可能同时在$S\\rightarrow M_u \\rightarrow D$的路径上。而路径$S\\rightarrow M_d \\rightarrow D$则未被使用。并且在一段时间以后Hedera意识到$f_{12}$是elephant流，因此将其转移到路径$S\\rightarrow M_d \\rightarrow D$。这样的情况下，所有流的平均FCT为0.2秒。\n如果流分类算法能在一开始就分辨出$f_{12}$是elephant，则可以将其放在下边的路径上。并且，可以将平均的FCT减少为0.12s。\n但是实际上，很难一开始就判断出一条flow是elephant。\n1.3 基于机器学习的算法 # 可以通过基于机器学习的算法来对flow的大小进行判断，并判断一条流是否为mice or elephant。 但是算法准确率并不能达到100%， 因此如果mice流被错误地判断为elephant流，那么就有可能导致其FCT增加。\n2 设计 # 2.1 流分类 # DarkTE使用 随机森林的方式来实现对流分类。随机森林的主要思路就是从样本中可放回地随机采样N组样本(样本可以重复)，然后根据每组样本生成一个决策树。这样最后就会得到N个决策树。并且每个决策树只使用其中的一些feature来进行决策。（DarkTE中，这些feature就是数据集中关于flow的一些数据。由于使用机器学习类算法，因此也不关注feature实际的含义）\n例如决策树1，使用tcp queue 和 agg net in作为判断的feature。那么决策树2就可能使用agg net out 和 first call 作为feature。\n然后将flow放入N个决策树进行分类，每个决策树会根据这个flow的一些feature来预测这个flow的size。\n对于随机森林分类的结果，可以根据阈值的设定来将流分成mice 或者是elephant。 如果是被分成了Mice流，那么就采用ECMP的方式，将这个flow随机分到一条路径上。 如果是elephant流，则会继续后面的流程通过启发式来调整这条流的速率。\nconfidence score # 由于每个决策树都有一个预测值，有的高有的低。那么最大的预测值就是upper bound，最小的预测值就是lower bound。\n$$variance=\\frac{upper bound - lower bound}{prediction flow size}$$ $$confidence score = 1 - variance$$\n可以看到如果upper bound 和lower bound的差距越大，也就是说不同决策树预测的流大小差距越大，则说明对预测结果不准确，那么confidence就会很低。（不是很清楚分母的prediction flow size是什么意思，感觉换成upper bound也说得过去）\n2.2 速率分配 # DarkTE中，通过测量flow的速率（rate），然后将elephant流的速率进行调整来优化网络。后文中，通过测得的flow rate和随机森林预测的confidence score来对flow rate进行调整。\nDarkTE-D # DarkTE-D算法的目的就是不断地调用RATE-SRC （step 8）和RATE-DST (step 11)，在起点和终点对flow的速率调整，直到调整收敛。\nRATE-SRC # RATE-SRC是在源点对流进行调整。对于已收敛的flow，不再调整其速率，只是把其的速率加起来(step 5)来确定节点的剩余带宽。未收敛的flow，则将confidence加起来(step 6)。然后在step 11的时候(我认为不应该是1.0，而应该是节点的出口带宽),对于那些未收敛的flow，按照其confidence来将为分配的出口带宽进行分配。\n不过这样的分配只是让flow的速率和confidence成正比，只是满足了源节点的出口带宽，但可能超出了目标节点的带宽。\nRATE-DST # RATE-DST 在目的节点对flow rate进行调整。\nstep 16-19进行初始化，对所有目的节点为该节点的流的confidence和速率进行统计。\nstep 21-22则是判断进来的flow是否会占用完所有的带宽，如果占用不完，就不再调整了。（这一步也有问题，不应该是1.0，而是带宽）\nstep27-29在判断一个flow需求的带宽如果小于如果按照跟confidence正比的方式可以为它分配的带宽，那么就直接把这部分带宽分给这个流。（$d_S$是已经分配了的带宽，$S_C$是所有还没分配带宽的流的confidence 总和）\nstep 30-31 如果暂时还不能确定分配，就先记录为确定的flow的confidence的和，这样后续的步骤就能继续分配。\nstep 36-38 则是对那些是实在无法满足其带宽需求的flow(这些flow的要的速率太大，confidence又太小，导致无法通过step 27的判断)，则按照其confidence的比例将剩下的带宽进行分配。\n速率分配总结 # 可以看出，DarkTE首先通过随机森林的方式来估计一个流需要的速率（rate）,并给出确定的程度(confidence score)。然后根据这两个值，根据flow的源节点和目的节点的流的情况来调整实际分配给flow的速率。认真细看代码，可以发现，实际上是step 27先根据随机森林预测的流大小进行分配。实在不行才按照confidence的大小来分配。\n实际分配的速率有以下特点：\n节点的流的速率只和不会超过节点的带宽。 confidence越大，能分到的速率也就越多 2.3 路径选择 # 在一般的方法中，路径选择按照first-hit的原则。以找到的第一条路径作为使用的路径，并且先到的flow先选择路径。并且在选择路径的时候，总选择容量最大的路径。\n但是在某些情况下，可能导致有些流无法被分配。如左图中，flow按照$O_1$的次序，并且每条链路的容量是100Mbps。那么就会导致$f_4$因为链路容量不够而无法被分配。\n所以作者提出highest-confidence-first(HCF)的方法来安排流搜索路径的顺序。实际上就是先按照confidence score把流排序一次。然后按照排序后的次序来作为到达次序，先给confidence大的flow分配路径，再给小的分配。\n其实质上，是因为有些mice流被误判为elephant，从而会为他们分配很高的速率并导致带宽的浪费。所以要先给confidence高的流分配，这样来减少浪费。\n","date":"25 October 2022","permalink":"/posts/paperreading/darkte/","section":"Posts","summary":"1 背景 # mice流： 通常大小只有几KB的流 elephant流： 数据量很大，可以达到几个GB 1.","title":"[IWQoS'21]DarkTE: Towards Dark Traffic Engineering in Data Center Networks with Ensemble Learning"},{"content":" 背景 # 目前比较普遍的数据中心网络(DCN) 采用的是Clos架构: 网络由多级组成，从下到上依次是ToR 交换机，pod，spine. 其中ToR是机架顶部的交换机，ToR和pods相连，然后pods通过spine相连。\n这样的多层级的方式有一些弊端：太复杂的网络，这样的连接方式成本很高；不同pod pair之间的流量并不均匀，而网络本身只提供了均匀的pod 之间的带宽，因此会造成拥塞。\n因此在Gemini中提出了一种无spine(spine-free)的架构。Pod之间通过接线板(patch panel)或者是光路交换(Optical Circuit Switching, OCS)直接相连。在这种架构中，不同的Pod是直接相连的，例如Pod A $\\rightarrow$ Pod B。但也可以通过一些间接的方式相连，如Pod A $\\rightarrow$ Pod C $\\rightarrow$ Pod B。\n传统的方式中，Pod之间使用Spine switch相连，上行和下行链路已经固定，无法改变网络拓扑。而在OCS中，可以通过光路的连接，让不同Pod的端口之间直接相连(而不是通过switch转发来间接相连)。\n并且，OCS中还可以根据需求，来改变不同Pod之间相连的端口数目，以此来增加Pod中间的链路容量并满足业务的需求。\n作者通过调研不同的数据中心网络发现了一些流量特征：\nPod之间的流量并不均匀。少部分(30%)的Pod对(pod-pair)占到全网络中的大部分流量(80%) 大部分网络流量可以预测。大部分的Pod对之间的流量都不会超过之前7天中的最大流量。如果用DMR来代表后一天流量占前7天最大单日流量的比例。那么大部分的DMR都不会超过1。 少部分情况下，后一天的流量会超过前7天的最大单日流量，也就是DMR超过1.这是由于网络中的burst（突发流量）造成的。并且这种burst可能相当多，会显著超过前7天的最大单日流量，导致DMR远超过1.由于burst量大，会导致链路的利用率上升并导致延迟增加和丢包，所以必须处理burst的情况。 思路 # 所以在Gemini中，主要目标有两个：\n通过改变拓扑来动态调整Pod之间的链路容量（拓扑工程，ToE） 通过改变Pod之间不同路径上的分流比，来降低链路的复杂(流量工程，TE) 由于大部分情况下，Pod间流量是可以预测的。所以可以根据以往的Pod之间的流量，来重新分配Pod之间映射的端口数目。如果Pod之间的流量大，那么这两个Pod之间就会有更多的端口被映射到一起，也就拥有了更大的链路容量。\n而对于不好预测的burst，则讲这部分流量在多条路径上分配(Gemini中的spine-free架构是，pod A到pod B有一条直接相连的路径，和多条间接相连的路径，如Pod A $\\rightarrow$ Pod C $\\rightarrow$ Pod B)，以降低直接相连的链路负载。\n实现 # 在Gemini的实现中，一共分为了三步，分别为：分配Pod间的端口映射来降低MLU， 调整分流比，用额外的路径来均衡burst对网络的影响(hedging)，降低路径的冗余程度(stretch)且降低延迟。\n符号 含义 $\\mathcal{V}$ Pod集合 $\\mathcal{E}$ Pod之间的逻辑链路(logical trunk, 端口汇聚) $\\mathcal{T}$ 流量矩阵TM集合(过去一段时间的)，并且这些TM是过去一段时间的真实TM的逐元素最大值。例如2个时间点，PodA 到 PodB及PodC的流量分别为(100,200)和(300,150)。那么逐元素最大值的结果就是(300,200)，这相当于是以过去的真实流量为参照构建的一种最坏情况下的流量矩阵 $d_{i,j,t}$ 在第$t$个TM中，$Pod_i$到$Pod_j$的需求demand $f_{i,j,p}$ $Pod_i$到$Pod_j$在路径$p$上的分流比 $R_i$ $Pod_i$的端口数目 $s_i$ $Pod_i$端口的上行速率 $n_e$ 逻辑链路$e$中包含的实际链路数目(端口汇聚的数目) $C_e$ 逻辑链路$e$的容量 $s_e$ $s_e=min(s_i, s_j)$ 降低MLU # 第一步，由于大部分情况下，Pod对之间的流量都不会超过前7日最大流量，所以可以通过历史的流量矩阵TM来规划Pod之间端口汇聚的数目。如果是流量比较大的Pod对，那么其逻辑链路就需要更大的容量。\n通过将网络的问题，转化为优化的问题，可以得到下面的优化方法。\n公式1: 定义了最大链路利用率(MLU)的变量$u$。并且这是在过去一段时间的TM集合上的最大链路利用率。$f_{i,j,p}\\cdot d_{i,j,t}$代表的是在流量矩阵$TM_t$的状况下，在路径$p$上会受到的负载。如果逻辑链路$e$在路径$p$上，那么也会受到相应的负载。通过遍历所有的Pod对(也就是$i$和$j$的组合)，就可以得到逻辑链路$e$的整体负载。 公式2: 一些限制条件，定义了逻辑链路的容量$C_e$，链路速率$s_e$ 公式3: 源于$Pod_i$的逻辑链路$e$的分配的端口数目之和，不能超过$Pod_i$已有的端口总数目 公式4: 基本限制，分流比不小于0，分配的端口数目不小于0 在第一步中，真正需要确定的变量是$n_e$，也就是分配的端口的数目，这个数目在将来也不会发生改变。而分流比则可能在后续的步骤中改变。\n通过这一步，可以得到最佳的分流比 $u^*$ . 不过值得注意⚠️的是，由于 $\\mathcal{T}$ 中的TM都是逐元素最大值得到的，因此这些TM代表了一种几乎不会发生的最坏情况。所以这个$u^*$一定是高估的。\nhedging降低burst带来的负载 # 通过第一步,已经确定了Pod之间的端口聚合的数目，也就是确定了Pod之间逻辑链路的容量。但是在发生burst的时候，有些burst的流量很大，容易对逻辑链路造成较大的负载，因此需要把burst流量转移到其他路径上。\n在这一步中，$r$代表burst带来的额外的链路负载率。由于在上一步中，端口聚合的数目已经确定，这一步真正的变量是分流比。\n公式5：保证分流比的调整，以降低burst造成的负载。并且不会让链路利用率超过上一步得到的$u^*$. 公式6：burst在各条路径上造成的负载的表达式 可以看出，这一步的主要目的就是在有burst的情况下，调整分流比，以降低burst对逻辑链路的负载。\n通过优化，可以得到最小的额外链路负载$r^*$\n降低stretch # 由于从$Pod_i$到$Pod_j$有多条路径可以到达，但是如果所经过的路径太长，则会在经过的每条逻辑链路上造成负载。 为了用数学描述，stretch定义为所有逻辑链路的流量总和处以总的Pod之间的demand。\n如果每次都选择较长的路径，那么则会导致分子增加，stretch也增加。 所以优化目标可以公式化为： 优化目标：也就是stretch的分子，即每条逻辑链路上的负载总和 公式7: MLU不能超过第一步定下的MLU 公式8: r值不能超过第二步求到的r值 可以看出，公式7和公式8的目的就是为了对结果进行限制，以避免优化模型无限度地追求低stretch，而放弃了低MLU和低burst负载。\n关键TM # 在上述的3个步骤中，可以看到每个优化问题都考虑了TM集合$\\mathcal{T}$中的TM，因此如果集合$\\mathcal{T}$中的TM太多则会导致优化问题有更多的变量和限制条件。因此$\\mathcal{T}$中只只用了一些关键的TM，而不是过去一段时间内所有的TM。\n在Gemini中，使用聚类的算法，将所有的TM归为几个类。对于每个类，计算所有TM的逐元素最大值来作为关键TM。并在重配置中使用关键TM。\n","date":"21 October 2022","permalink":"/posts/paperreading/gemini/","section":"Posts","summary":"背景 # 目前比较普遍的数据中心网络(DCN) 采用的是Clos架构: 网络由多级组成，从下到上依次是ToR 交换机，pod，spine.","title":"[arxiv'21] Gemini: Practical Reconfigurable Datacenter Networks with Topology and Traffic Engineering"},{"content":" sendpfast不返回 # 在scapy中可以通过 sendpfast接口来以一定的Mbps速率发送loop个包。该接口的本质就是调用 tcpreplay命令来实现定速发包。\n也就是说，如果我想要在10s内以Mbps的速率发送包，那么只需要计算出来loop的个数即可。\n但是在实际使用过程中，在一些极端情况下会遇到一些麻烦。\nloop == 1 # 如果10s内发送多个包，那么tcpreplay会在运行10s中之后结束，此时sendpfast接口也返回了。但是如果在10s内仅发送1个包，那么tcpreplay就会在发送后立即结束，sendpfast也会立即返回。如果在一个循环中调用sendpfast，那么讲导致实际的速率和理想的差距很远。\nloop == 0 # 此时，tcpreplay将不会返回，也不会发包。在我的程序中，我使用sendpfast来发包，完成后读取新的Mbps。但是当速率太小，以至于10s中一个包也发不出来，那么sendpfast将一直阻塞。也无法读取新的Mbps。\n","date":"3 September 2022","permalink":"/posts/scapy/","section":"Posts","summary":"sendpfast不返回 # 在scapy中可以通过 sendpfast接口来以一定的Mbps速率发送loop个包。该接口的本质就是调用 tcpreplay命令来实现定速发包。","title":"Scapy 踩坑实录"},{"content":"","date":"21 August 2022","permalink":"/categories/","section":"Categories","summary":"","title":"Categories"},{"content":"","date":"21 August 2022","permalink":"/categories/scapy/","section":"Categories","summary":"","title":"Scapy"},{"content":" How to extract custom header from raw bytes using Scapy # 自定义协议 # 有些时候，需要构造一些自定义的协议以完成某些功能。但是这些协议不属于Scapy中已知协议的一部分，因此Scapy无法自动的将数据流中的raw bytes解析为已知的协议。因此，需要经过一些手动的步骤来完成解析。\n构造自定义协议 # Scapy中已经内置了一些常见的协议，可以非常方便的构造给予这些协议的包。\n常用协议 # 例如，构造一个Ether+IP的包\nimport scapy.all as scapy pkt = scapy.Ether(src=\u0026#34;ff:ff:ff:ff:ff:ff\u0026#34;,dst=\u0026#34;ff:ff:ff:ff:ff:ff\u0026#34;)/scapy.IP(src=\u0026#34;127.0.0.1\u0026#34;,dst=\u0026#34;233.233.233.233\u0026#34;) pkt.show() print(scapy.raw(pkt)) 输出如下\n###[ Ethernet ]### dst = ff:ff:ff:ff:ff:ff src = ff:ff:ff:ff:ff:ff type = IPv4 ###[ IP ]### version = 4 ihl = None tos = 0x0 len = None id = 1 flags = frag = 0 ttl = 64 proto = ip chksum = None src = 127.0.0.1 dst = 233.233.233.233 \\options \\ b\u0026#39;\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\x08\\x00E\\x00\\x00\\x14\\x00\\x01\\x00\\x00@\\x00(\\x15\\x7f\\x00\\x00\\x01\\xe9\\xe9\\xe9\\xe9\u0026#39; 可以看到，直接指定layer的名字即可构造一层。其中layer的内容有默认值，也可以如上所示在构造的时候指定某些字段的值。\n构造协议 # 在Scapy中，如果要构造一个layer，只需要一个新的类继承Packet即可，并制定新的layer有哪些字段。\nclass MyLayer(scapy.Packet): name = \u0026#34;my layer\u0026#34; fields_desc=[ scapy.BitField(\u0026#34;first\u0026#34;,0,size=4), scapy.XBitField(\u0026#34;second\u0026#34;,0,size=4) ] 可以看到，自定义的header中，有两个字段。一个是长4bit的字段，第二个也是长4bit的字段，不过用16进制的方式显示。\n构造一个有自定义协议的包\npkt = scapy.Ether(src=\u0026#34;ff:ff:ff:ff:ff:ff\u0026#34;,dst=\u0026#34;ff:ff:ff:ff:ff:ff\u0026#34;)/MyLayer(first=6,second=0xf) pkt.show() print(scapy.raw(pkt)) ###[ Ethernet ]### dst = ff:ff:ff:ff:ff:ff src = ff:ff:ff:ff:ff:ff type = 0x9000 ###[ my layer ]### first = 6 second = 0xf b\u0026#39;\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\x90\\x00o\u0026#39; 解析自定义协议 # 在Scapy中，使用sniff可以自动嗅探网卡，并将得到的数据包的数据给解析为对应的字段。不过本例中不使用该方式，而是将一个包转化为raw bytes，再将raw bytes转化为包。\npkt = scapy.Ether(src=\u0026#34;ff:ff:ff:ff:ff:ff\u0026#34;,dst=\u0026#34;ff:ff:ff:ff:ff:ff\u0026#34;)/MyLayer(first=6,second=0xf) raw_bytes = scapy.raw(pkt) new_pkt = scapy.Ether(raw_bytes) new_pkt.show() 输出如下\n###[ Ethernet ]### dst = ff:ff:ff:ff:ff:ff src = ff:ff:ff:ff:ff:ff type = 0x9000 ###[ Raw ]### load = \u0026#39;o\u0026#39; 可以看到，此时只能将raw bytes解析为Ethernet，无法继续解析。此时除了人Ethernet层以外的字节被当作了payload，但payload具体是什么还不知道，因此需要告诉scapy下一层是什么。\nnew_pkt.decode_payload_as(MyLayer) new_pkt.show() 输出\n###[ Ethernet ]### dst = ff:ff:ff:ff:ff:ff src = ff:ff:ff:ff:ff:ff type = 0x9000 ###[ my layer ]### first = 6 second = 0xf 可以看到scapy正确的解析了MyLayer层，并得到了和构造包的时候相同的字段值。\n","date":"21 August 2022","permalink":"/posts/extractheader/","section":"Posts","summary":"How to extract custom header from raw bytes using Scapy # 自定义协议 # 有些时候，需要构造一些自定义的协议以完成某些功能。但是这些协议不属于Scapy中已知协议的一部分，因此Scapy无法自动的将数据流中的raw bytes解析为已知的协议。因此，需要经过一些手动的步骤来完成解析。","title":"如何使用Scapy从raw bytes中提取自定义Header?"},{"content":" 文章背景 # 目前的TE解决方案中，比较常见的方式是预先计算节点到节点之间的多条路径，然后在这些路径上调整分流比例。而该文章中，作者采用的方式则是与OSPF进行结合。文章提出的方法是通过强化学习 + GNN的方式来调整链路的权重，然后让OSPF按照自己的方式，根据链路权重和Dijkstra算法来计算路径。\n解决方案 # 该方案中，首先使用一个GNN来提取网络的link与邻居的特征，然后再把提取到的特征送入DRL，DRL计算得到需要执行的动作。\nGNN # 该方案中采用的GNN是MPNN，link将自己的初始权重和链路利用率作为自己的初始hidden state，然后将自己的hidden state和邻居link交换。再将收集到的所有hidden state经过一个全连接层，再来一次逐元素相加，一个全连接层得到一个新的hidden state。重复这个步骤得到一个link最终的hidden state。\nDRL # 该方案的DRL采用PPO算法，主要是将GNN输出的hidden state计算得到一个最终的概率。并以这个概率进行采样，根据采样结果来决定是将权重增加1还是减少1。可以看到DRL的结果并直接就是link的权重。\n思考 # 感觉这个算法优点浪费计算资源，每次经过那么多的迭代就得到一个对一条link权重的增减，感觉其实可以根据提取到的特征来做更多的事情 原文中有将DRL计算得到的概率在agent之间共享，并且每个agent都共享相同的随机种子。按照原文的说法，这样的话每个agent都可以去采样得到相同的结果。但是我感觉这样并不是很有意义，因为采样是一个很简单的工作，结果还需要去增加共享开销 经过那么多的计算量，最终做的事情知识将权重增加或者减少一点点。这样会不会导致对于网络状况的反应不够迅速？例如对于突然产生的拥塞调整的太慢 ","date":"11 April 2022","permalink":"/posts/paperreading/marlgnn/","section":"Posts","summary":"文章背景 # 目前的TE解决方案中，比较常见的方式是预先计算节点到节点之间的多条路径，然后在这些路径上调整分流比例。而该文章中，作者采用的方式则是与OSPF进行结合。文章提出的方法是通过强化学习 + GNN的方式来调整链路的权重，然后让OSPF按照自己的方式，根据链路权重和Dijkstra算法来计算路径。","title":"[ICNP'21] Is Machine Learning Ready for Traffic Engineering Optimization? 阅读笔记"},{"content":"","date":"11 April 2022","permalink":"/categories/graph-neural-network/","section":"Categories","summary":"","title":"Graph Neural Network"},{"content":"","date":"11 April 2022","permalink":"/categories/reinforcement-learning/","section":"Categories","summary":"","title":"Reinforcement Learning"},{"content":"","date":"11 April 2022","permalink":"/categories/traffic-engineering/","section":"Categories","summary":"","title":"Traffic Engineering"},{"content":"","date":"11 April 2022","permalink":"/categories/%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/","section":"Categories","summary":"","title":"阅读笔记"},{"content":" 1 文章背景 # 目前的Traffic Engineering主要有两种方式：中心式和分布式。\n中心式既一个控制器控制整个网络，好处是这个控制器知道整个网络的信息，理论上来说可以得到最优的解。但是坏处是随着网络规模的扩大，中心式的算法的复杂度急剧提升，以至于花几个小时才能得到一个最优解，因此很难对网络状况的改变作出快速的反应并调整网络。\n而分布式的TE在扩展性方面就会好很多。该文章FedTe采用的就是分布式TE的方式。\n2 解决方案 # 在FedTe中，一个网络被划分为了多个域（region），每个region有一个控制器。针对不同类型的流，控制器有不同的处理方法。例如，如果是域内的流，由于每个域的规模有限，可以采用线性规划的方法来得到最优的解。如果是跨域的流，则使用GNN来学习如何去控制不同区域之间的流。为了让控制器了解整个网络其他区域的信息，FedTe采用联邦学习的方式，每个区域控制器的GNN在提取了本区域的网络特征以后都会和其他的区域控制器交流，供其参考。\n在FedTe中，先通过离线的方式来计算全局的最优解，然后离线让GNN学习这个全局最优解是如何来操控跨域的流。在该文中，控制器操控流的具体方法就是首先计算网络内任意两个节点对(pair)之间的多条路径，然后控制流量在这些路径上面的分割比例。\n因此，首先要计算出任意两个节点之间的路径，并计算全局最优解。\n2.1 全局最优解 # 首先通过obliviou routing algorithm来计算多个节点之间的路径，然后会删除其中的一些路径：1、一个域送到了另一个域，然后又被送回来 2、源节点和目的节点都在同一个域，但是计算出来的路径却进入到了其他的域。\n确定了路径后，通过解MCF(Multi-Commodity Flow)问题来得到全局最优解。\n2.2 GNN模型 # 在有了全局最优解以后，GNN便有了学习标杆。为了让GNN作出的决策更具有全局思维，FedTe采用了联邦学习的方式，每个区域的控制器将提取到的区域的网络特征和其他控制器交流，让后者了解本区域的情况。\n因此，GNN的模型分为了三个部分：\nIntra-Region Encoder: 负责提取一个区域的网络的特征 Inter-Region Encoder: 综合不同区域的网络的特征 Decoder: 根据网络特征来计算任意两个节点之间的多条路径上流量的分割比例。 2.2.1 Intra-Region Encoder # Intra-Region Encoder的输入是一个区域内所有真实节点和一个虚拟的controller节点的feature。并且所有的节点都是单向连接到controller 节点。因此可以构造一个连接矩阵。根据GNN的算法，每一次迭代，一个节点都会获得其邻居的feature（这就是为什么要输入连接矩阵，就是为了知道某个节点和哪些节点相连）。迭代一次以后就可以得到距离为1的节点的信息，迭代2次以后就能得到距离为2的节点的信息。在迭代$H$次以后就能得到距离为$H$节点的信息。\n这样的方法下，经过了多次迭代以后可以认为$h_{C0}$拥有了整个区域的信息。因此每个控制器只需要讲自己的$h_{Ci}$和其他控制器交换即可。\n2.2.2 Inter-Region Encoder # 在获得了其他区域的特征信息以后，将区域内每个节点的特征和其他区域的特征输入Encoder即可得到拥有全局视野的区域网络特征。\n2.2.3 Decoder # 将Inter-Region Encoder得到的特征作为Decoder的输入，经过全连接层得到任意两个节点的不同路径之间的分割比例。\n3 思考 # FedTe中先计算最优解再让GNN学习的方法比一般的基于强化学习的方法在训练上要快许多。可能的原因是强化学习需要在不同的可能性之间不断的尝试，这中间可能包含了很多无效或者错误的尝试。而FedTe的训练方法则只需要让GNN尽量去模仿就好了，至少目的上是非常明确的。\nFedTe还有个好处则是在于每个controller对其他区域的状况并不是一无所知的。例如在MRTE中，对某个controller来说，基本上是不了解其他区域的状况的，只能通过把其他区域的reward加到自己的reward上来看自己的决策好不好。\n另一个不错的地方就是对于区域内部的流直接使用了线性规划的方式来求的最佳的解，因为LP在小规模的情况下计算速度还是比较快的。\n","date":"29 March 2022","permalink":"/posts/paperreading/fedte/","section":"Posts","summary":"1 文章背景 # 目前的Traffic Engineering主要有两种方式：中心式和分布式。","title":"[ICNP'21]Federated Traffic Engineering with Supervised Learning in Multi-region Networks 阅读笔记"},{"content":"","date":"29 March 2022","permalink":"/categories/gnn/","section":"Categories","summary":"","title":"GNN"},{"content":" 1、背景 # 在目前的云方案中，每个云有很多个出口节点，连接不同的ISP。每个ISP根据链路的使用量来进行计费。具体的计费方式如下：\n计费周期为1个月，在这一个月中每5分钟统计一次，这5分钟称作一个slot，那么一个月就是8000+个slot。然后ISP每个slot把流量统计一次，然后一个月过后把所有流量大小排序，然后把95百分位(排名在95%位置)的流量大小$z_i$作为这个月的流量，乘以单价$c_i$就是总的价格，也就是$\\Sigma z_i*c_i$。\n2、优化方案 # 通过计费模式，可以明确优化的思路。就是让链路在大部分时间(95%)保持一个很低的速率，这样的话最终的统计结果中95分位的流量$z_i$就会很低，从而降低总的费用。但是这样做也会衍生出一些问题：\n进入云的流该如何优化 速率降低以后整个云中的流量应该如何出去 在计费方式中，一条链路在一个slot中的流量是按照进入和出去的流量中取较大者，经过作者的统计，云中出去的流量是进入流量的两倍，所以针对第一点的优化方法就是不优化。\n针对第二点，由于一个云都有很多条出去的边缘链路，也就提供了更多的能力把整个云中需要发出去的流量在多个链路之间调节。该文的优化方向就是通过调整每个出口链路上的流量，从而降低95分位流量$z_i$和总的费用。\n上图中，横轴是每个slot中流量的大小，竖轴是分布的密度。可以看到Link A 中，反向优化以后95分位的流量增大导致费用增加，而Link B 中优化以后95分位流量降低所以让费用降低。\n离线方案 # 在离线方案中，作者假设是知道每个时间段的流量\n上述的解决方案可以看作是一个线性规划寻找最优解的问题，目标就是最小化$\\Sigma z_i * c_i$ 。但是由于$z_i$是一个95分位的值，所以这个优化问题是一个NP-Hard的问题。作者的方法是把问题转化为一个 k-max 问题。\n变量 含义 $x_{ij}$ 链路i在第j个slot的时间段内的流量 $\\lambda_{ij}$ 链路i在第j个slot的流量是否超过了链路i在整个计费周期的95分位 $C_i$ 链路i的容量 $d_j$ 第j个slot中的流量需求 $z_i$ 链路i的95分位的那个流量大小 $M$ 一个很大的数 上图的算法中，每个计费周期中有$n$个slot，$k$是95分位的slot，也就是说有$k-1$个slot的流量是大于95分位流量的。\n上图算法中的四个限制条件是：\n任意时刻链路流量不超过链路容量 任意时刻总的流量和该时刻的需求量相同 一共有k-1个slot的流量大于95分位流量$z_i$ 检验对于一个流量是否大于95分位的标记($\\lambda_{ij}$)是否正确。如果流量大于95分位的流量，也就有$x_{ij} \u0026gt; z_i$, $\\lambda_{ij}$ = 1，而$M$又是一个很大的数，那么不等式成立。同理流量不大于95分位的流量的情况下不等式也是成立的 解上面的算法大概需要几个小时，作者通过线性规划松弛的方式可以将时间减少到1-2小时，但是结果比最优解差一点。通过使用上个月的解来作为本月的初始值也可以将计算时间减少到2小时。\n在线方案 # 在线方案可以简单的理解为老师让几个同学们打扫卫生，任务量比较少的时候，所有同学都可以比较低效的来打扫卫生。如果某一天的任务很多，以至于所有同学低效打扫都不能完成任务，那么老师就会叫其中几个同学全力打扫，但是每个同学全力打扫的时间不超过总时间的5%。\n在线方案中有以下的变量：\n变量 含义 $C$ 整个出口网络的总容量 $f$ 一个比例，需要对它进行调节 $d$ 某个slot的需求 $C_f = f* C$ 一个阈值，如果需求量没有超过这个阈值，那么每个链路用很低的速率(这个速率就是链路自身的速率 * $f$)即可，如果需求量超过了这个阈值，就需要某些链路全速运行 算法如下\n一开始的时候，每个链路都有一个freeslots计数器来统计自己可以全速运行的slot数目。\n如果需求量小于阈值($d \\leq C_f$)，说明所有链路按照一个低速运行也可以应付，所以就从链路集合$L$中选择一些即可，选择的方法是按照装箱问题来选择，也就是所选择的链路的低速速率之和超过需求$d$最少。\n如果需求量大于阈值，就从优先级队列中取出一些链路（augmented_links）来全速运行。并减去这条链路还可以全速运行的slot的数目，也就是link.free_slots。\n不可行的$C_f$：由于$C_f$设置的太小，导致频繁的触发一些链路全速运行，消耗其free slots，导致到了接近月末的时候，遇到大的需求量的时候没有足够的链路可以全速运行来满足这个需求量。\n如果遇到了这种不可行的状况，那么就需要增加$f$的值，从而让$C_f$增加。这样的做法相当于是提升了「低速运行」时的速率。可以遇见，这样的做法会导致95分位的那个流量的大小增加，从而增加了总的费用。\n3、思考 # 代码的一些问题 # bin_pack(L,d) 似乎要更合理一些，也就是根据具体的需求量来分配需要的链路，而不是根据一个几乎固定的阈值。 if b_link in L1 文中有提到$L_1$是某个价格的links的集合，但似乎代码中表达的意思是上个slot中已经使用的链路。 代码中的优先级link.prio 和全速工作的slot数目link.free_slots是等价的，但是原文中优先级应该有更复杂的计算，例如上个slot中被选中全速运行的链路应有更高的优先级，以保证不同的slot之间工作的链路不会频繁的切换，造成性能损失。 代码中如果需求大于阈值，那么选中的链路都会需要开启全速运行的模式。这样似乎不太聪明，如果有10条链路，采用【9条低速+1条全速】的方式肯定比【2条全速】的方式好，因为这样可以节省一些免费的slot 其他问题 # 相比于文中$C_f$不够用了再调大的方式，如果一开始就能选择一个比较大的阈值$C_f$，导致从来不会出现「不可行」的情况，会不会更加省钱？\n","date":"28 March 2022","permalink":"/posts/paperreading/cascara/","section":"Posts","summary":"1、背景 # 在目前的云方案中，每个云有很多个出口节点，连接不同的ISP。每个ISP根据链路的使用量来进行计费。具体的计费方式如下：","title":"[NSDI'21]Cost-Effective Cloud Edge Traffic Engineering with CASCARA 阅读笔记"},{"content":"","date":"28 March 2022","permalink":"/categories/greedy-algorithm/","section":"Categories","summary":"","title":"Greedy Algorithm"},{"content":" 1、文章背景 # 在目前的多控制器SDN中(MCSDN)，需要去维护多个控制器之间的一致性。如果是要维护强一致性(strong consistency)就需要产生大量的开销，而如果使用最终一致性(eventual consistency )则可能会导致controller基于过时的信息来作出决定。\n2、解决方案 # 作者提出的办法是使用分级的controller来控制整个网络，分为Local Controller(LC)和Root Controller(RC)。具体方式就是将整个WAN网络分成多个区域，每个区域中的所有switch由几个LC控制。然后RC则无需直接控制下层的switch，而只需要控制每个区域的LC。\n这样分层的方法有一些好处：\n减少了controller之间需要共享的信息量，并减少同步开销 限制了链路错误的影响范围 分层设计 # Local Controller # 在Helix中，LC来控制一个区域中的所有switch，由于LC了解每个区域中的拓扑，所以LC可以轻易决定区域内部的路由。\nRoot Controller # 为了简化RC维护的内容，Helix中的RC不在保存整个网络的拓扑，而是将每个区域进行简化。对于RC来说，只能看见每个区域的三个部分：\n边界路由器 border switch 主机 host 其他 这样简化以后，RC不再关心区域内部的状况。\n路径计算与TE # 首先，预先计算区域内任意两点之间的多条路径(Dijkstra)，如果某条路径挂了，就可以在LC不干预的情况下启用另一条路径(快速故障恢复 fast-failover)。\n在Helix中，RC只负责计算和维护跨区域(inter-area)的节点之间的路径计算。类似于LC计算路径的方式，RC也是用Dijkstra来计算多条路径。计算完成后，RC会将这些路径的信息下发到下面的LC中。但是这些路径只包含边界上的节点(RC只清楚边界上的节点)，至于这个路径在某个区域中具体是怎样的，就由LC来决定。\nTraffic Engineering # LC 不断的统计两点间流量的大小,然后从大到小排序，希望把大的流量转移到新的路径上面去。计算新的路径的前首先会先排除那些负荷很大的链路，然后在剩下的没有被排除的链路上使用Dijkstra算法来计算新的路径，这样就可以把流量转移到不那么拥挤的链路上。\n对于一个inter-area的流量，LC是无法决定这个流量从哪个边界节点进入，但是可以决定这个流量从哪个边界节点出去。正如之前所讲，RC会计算很多条路径，所以LC其实知道某个流量可以从哪些节点出去。例如上图的例子中$f$原本是从$S_2$的a端口出去，但也可以从$S_3$的b端口出去，如果$S_2$的a端口很拥挤，那么LC可以自己决定让这个流量通过$S_3$的b端口出去。在这么做了以后只需要通知RC一下即可。\n3、总结 # Helix 主要的目的是为了减少controller之间为了追求强一致性而带来的开销。因此采用了分级的设计，LC管理一个区域，而RC管理这些LC。大部分情况下LC自己就可以完成TE的目标，而完全不用告诉RC。这样也就避免了频繁的在controller之间进行同步。其次，RC也不再关心一个区域内部的细节情况，也就减少了controller之间需要同步的内容。最后由于采用了遇见计算路径的方式，在遇到链路故障的情况下，可以在controller不参与的情况下尽快的切换路径。\n疑惑：\n不一定降低整体的链路利用路：由于TE大部分下是LC完成的，也就缺少全局观，并且LC只是让流量不经过拥塞的链路，而不是在整体上降低链路利用率。只要某条链路没有饱满就会继续使用，这样可能出现有些链路很拥挤而另一些很空闲的情况。 ","date":"22 March 2022","permalink":"/posts/paperreading/helix/","section":"Posts","summary":"1、文章背景 # 在目前的多控制器SDN中(MCSDN)，需要去维护多个控制器之间的一致性。如果是要维护强一致性(strong consistency)就需要产生大量的开销，而如果使用最终一致性(eventual consistency )则可能会导致controller基于过时的信息来作出决定。","title":"[SOSR'21]Helix: Traffic Engineering for Multi-Controller SDN 阅读笔记"},{"content":"","date":"22 March 2022","permalink":"/categories/software-defined-network/","section":"Categories","summary":"","title":"Software Defined Network"},{"content":" 一般 # 踩坑😢 指南🧭 手动git clone可以，但是运行脚本中的git就会报错gnutls_handshake() failed: Error in the pull function. 设置git proxy的时候用的是普通用户，但是执行脚本的时候用的是sudo，导致git proxy在sudo没有生效.【设置git proxy使用sudo即可】 Mac m1 下的虚拟机方案 parallels虚拟机 Mac m1 parallels安装ubuntu失败 不使用ubuntu iso安装，直接使用parallels内下载的ubuntu Parallels中的ubuntu无法开机，提示：“ kernel image not aligned on 64K boundary” 开机的时候GRUB界面进入\u0026quot;Advanced options for Ubuntu\u0026quot;（没有的话就重启下虚拟机）,选择\u0026quot;5.13.0-25-generic\u0026quot;,不想每次选的话可以 这样 P4 # 踩坑😢 指南🧭 P4-utils 执行p4run命令提示找不到module p4utils.mininetlib.p4net 在p4app.json 中改为p4utils.mininetlib.net P4-utils执行p4run时并没有编译p4 程序 第一行写\u0026quot;p4_src\u0026quot;:\u0026ldquo;xxx.p4\u0026quot;来包含源代码，\u0026ldquo;program\u0026rdquo;:\u0026ldquo;xxx.p4\u0026quot;的方式是无效的 找不到p4_logger 不确定是不是被改成了log_msg了，但是可以用log_msg(\u0026quot;Value1 = {}, Value2 = {}\u0026quot;,{value1, value2}); p4-utils中的mac地址是随机的 可以把p4app.json中的\u0026quot;assignment_strategy\u0026quot;设置成\u0026quot;mixed\u0026rdquo; ","date":"18 March 2022","permalink":"/posts/caikeng/","section":"Posts","summary":"一般 # 踩坑😢 指南🧭 手动git clone可以，但是运行脚本中的git就会报错gnutls_handshake() failed: Error in the pull function.","title":"奇葩踩坑日常"},{"content":" 1、文章背景 # ECMP的局限性 # 文章提出的WCMP算法就是基于多路径的ECMP算法的一些问题进行的改进。在ECMP算法中(图a)，从S10点到S12点会事先计算几条等价路径，然后把从S10点到S12点的所有流在这些路径上进行均匀的分配。 但是这样的做法有个问题：从S10到S20有两条链路，每条路径3个流，但是从S20到S12就只有一条链路，但上面却要挤6条流。不同link上流的数目差距很大。每个流能用的带宽下降，从而导致整体的性能下降。\n因此作者提出WCMP，要求流在各个路径上的分配不再是均分，而是根据权重来进行分配，在图b中不同路径上的流的数目不同反而能让整体有更好的性能。\nECMP为什么不行？ # 网络的结构并不对称，有些switch连接很多的switch，但另一些却很少 网络错误的发生。即使发生的几率很小，也会在发生时改变网络状况，而ECMP并没有考虑到这些错误发生时的链路容量的变化 2、减少表项设计 # 多路径表的设计 # 在WCMP中设计了两张表，第一张表(左)是WCMP group的表，记录了：\nIP 前缀(判断一个包属于哪个group) 这个group在第二张表中的起始位置 这个group在第二张表中有多少个表项 第二张表(右)则是一些出口端口的编号。\n所以决定一个包走哪条路径（出口端口）的过程如下：\n根据目的IP判断属于哪个WCMP group -\u0026gt; 根据流的源目的IP，源目的端口来Hash得到一个值，把这个值与group的表项数目取模得到group内索引号 -\u0026gt; group内索引号 + group的起始位置得到出口端口在第二张表中的位置 -\u0026gt; 将包转发到第二张表记录的端口上\n从上图可以看出，WCMP每个端口的权重（整数）等于其对应的表项数目，一个端口的权重越大，表项也就越多，那么Hash选中这个端口的概率也就越大。\n这样的设计方式也就引入了新的问题：\n表项并不能无限多。由于转发工作需要硬件支持，但硬件并不支持太多的表项。因此也就需要减少表项，相应的也就是减少端口的权重的值。\n不过也不能随意的减少表项，实际中可能需要保证以下指标(当然可能并不能同时实现)：\n端口的负载不能增加太多 要把某个组的表项减少到某个程度 限制超额的情况来减少权重值 # 对于一个给定的WCMP组G，G中的端口和端口的权重已经确定。 首先，每个端口的流量需求$B_i(G)$和它的权重(weight)在整个group中的占比有关。\n每个端口需求量 因此，如果改变了端口的权重，那么有些端口的流量需求就会上升，因此就把这个上升的程度称为超额(oversubscription) , 超额的计算本质上就是看权重的占比的变化幅度。不过由于端口需求量的上升可能会造成拥塞，因此会希望超额越小越好。\n超额 这里作者采用贪婪算法的方式来计算改变权重,其实也可以使用解线性规划问题的方式来优化权重，但是后者计算的消耗巨大并且结果也没有好太多。\n首先针对待优化的WCMP组$G$来说，我们希望找到一个权重值跟小的组$G\u0026rsquo;$，首先把$G\u0026rsquo;$中每个端口的权重设为最小值1(每个端口至少需要一个表项),然后通过算法2来寻找超额最大者，并增加它的权重。\n算法1 限制超额的情况下减少权重 算法2 找到超额最大的端口 限制组的大小的情况下减少权重值 # 这种情况下，文中算法的做法是先给所有的端口按一定比例减少权重(但保证最低为1)。（前19行）\n算法3\n由于是按照比例减少，那么可能还会有几个多余的权重值来分配。这是选取超额值最大的端口，然后分配一个权重值给它。就可以减少这个端口上的多余负载。（20-31行）\n3、链路分配 # 链路分配（Striping）指的是DCN中的下层到上层的链路的分配。这个分配的方式决定了不同路径的容量以及WCMP组里面一开始的权重分配。由于在DC的网络拓扑 中，采用的是先上后下的方式，也就是说流会先从下层switch发到上层switch，再回到下层switch。因此如果某个下层switch和某个上层switch之间的link数目太多，就可能导致和其他的下层switch之间由于缺少足够的路径而导致容量降低。Striping简而言之就是连网线。\n难点 # 如果一个下层switch的上行链路(uplinks)的数目是上层switch数目的整数倍，那么也就可以保证每个switch得到的上行链路的数目是一样的。但很多时候实际情况这个比例并不是整数倍，因此有一些switch就可以多得到一些上行链路，如何分配这些多的上行链路也是非常重要的。文章中提出两种分配方式\nRotation Striping Group String (蓝色虚线是两条链路)\nRotation Striping # 该方法有点类似于发扑克牌的方法。\nS10依次连接一个uplink到S20-\u0026gt;S21-\u0026gt;\u0026hellip;S25-\u0026gt;S20\u0026hellip;\nS11依次连接一个uplink到S21-\u0026gt;S22-\u0026gt;\u0026hellip;S25-\u0026gt;S20\u0026hellip;\nGroup Striping # 通过上文的分析，可以知道上层switch跟下层任意一个switch相连的link数目要么是$p$,要么是$p+1$。换言之，下层switch与任意上层switch相连的link数目要么是$p$,要么是$p+1$。所以Group Striping的想法就是把下层switch进行分类到不同的分组，这些分组中的连接的link数目就只是$p$，或者只是$p+1$。例如S10和S11的link的数目就是相同的，所以S10到S11就有8条路径，也就有80Gbps的容量。\n但是不同的组之间例如S10和S12就只有6条路径，也就是60Gbps的容量。\n4、初始的权重分配 # 最大流最小割(max-flow min-cut)算法计算。\n5、总结 # WCMP过程： striping让每个switch之间更均匀的相连，尽量让两个switch之间的带宽大 -\u0026gt; 通过最大流最小割计算初始权重 -\u0026gt; 根据权重建立两个表 -\u0026gt; 通过两个算法来减少表的数目，利于硬件快速读取\n6、缺点 # 不可以对整个网络的拥塞状况进行感知，也就不能实时调整权重 ","date":"14 March 2022","permalink":"/posts/paperreading/wcmp/","section":"Posts","summary":"1、文章背景 # ECMP的局限性 # 文章提出的WCMP算法就是基于多路径的ECMP算法的一些问题进行的改进。在ECMP算法中(图a)，从S10点到S12点会事先计算几条等价路径，然后把从S10点到S12点的所有流在这些路径上进行均匀的分配。 但是这样的做法有个问题：从S10到S20有两条链路，每条路径3个流，但是从S20到S12就只有一条链路，但上面却要挤6条流。不同link上流的数目差距很大。每个流能用的带宽下降，从而导致整体的性能下降。","title":"[EuroSys'14]WCMP: Weighted Cost Multipathing for Improved Fairness in Data Centers 阅读笔记"},{"content":"","date":"14 March 2022","permalink":"/categories/data-center/","section":"Categories","summary":"","title":"Data Center"},{"content":"","date":"14 March 2022","permalink":"/categories/multipathing/","section":"Categories","summary":"","title":"Multipathing"},{"content":" 文章背景 # 目前的流量工程中，主要的目标就是降低整个网络中最大的链路利用率，也就是将流量分摊到整个网络中。在目前的基于深度强化学习(DRL)的解决方案中，有一些是调整路由的路径，又一些是调整流量在不同路径上的分割比例。\n但是这些基于DRL的方案在可扩展性上都有很大的问题，随着网络规模(节点数目$V$)的增加，神经网络的输入的规模将是$O(V^2)$,所以超过一定的规模以后，DRL将难以收敛。\n解决方案 # 本文的主要思路就是在于减少输入的量，作者使用了最为朴素的方式，也就是不在针对每个流或者是每个节点、链路进行控制，而是只针对某些链路进行控制。\n这样的链路被称为critic link，文中的解决方法就是动态调整critic link的权重，然后在实际使用中通过计算最短路径优先算法(Shortest Path First,SPF)来实现路由并降低最大链路利用率。因此整个解决方案也分为两个部分，一部分是离线阶段，这个阶段要从所有的链路中选出这些critic link。第二个部分是在线阶段，利用强化学习来调整这些critic link的权重。\n离线选Critic Link # 这个阶段就是要在所有链路中选出一些，供下一个阶段中调整权重使用。\n这里，针对所有的链路，最重要的指标就是中心度(centrality)，中心度的计算方式很简单，公式如下：\n$\\rho\\left(e_{m}\\right)=\\frac{\\sum_{i=1}^{|V|} \\sum_{j=1}^{|V|} x_{i, j}^{m}}{|V| \\times|V|}$\n先计算出图中任意两点$i,j$之间的最短路径，然后看链路$e_m$是否在这条路径上，是的话$x_{i, j}^{m}$就是1，把所有的节点遍历一遍就可以知道有多少的最短路径经过了链路$e_m$，再除以最短路径的总数就可以得到中心度。总之中心度描述了一条链路在图中的重要性。\n计算了中心度以后，需要根据中心度来选择哪些链路作为critic link，文章中选择的是中心度在中位数附近的那些链路，并不是中心度最高或者最低的链路。以下面的例子来讨论原因：\n在上图的拓扑中，计算的是每个链路的中心度(权重均为1)。可以看到$e_7$有最大的中心度33，$e_2$有最小的中心度2。\n如果提高$e_7$的权重到2以上，那么从$v_1,v_2,v_3,v_4$到$v_7,v_8,v_9,v_10$之间的最短路径就完全不会经过$e_7$。如果权重小于2，那么大部分从$v_1,v_2,v_3,v_4$到$v_7,v_8,v_9,v_10$的流都会经过$e_7$。\n如果是调整$e_2$，由于$e_2$的中心度太小，这样的调整对于整个网络的链路利用率的改善是十分有限的。\n综合上述的分析可以知道，中心度太大和太小都不是很好，因此critic link的选取标准就是在中位数附近的中心度。\n在线调整权重 # 调整权重使用的是强化学习中的ACKTR方法，这是一个基于actor-critic方法。actor根据输入的状态$state$计算得到输出动作$action$，action表示的是每个critic link调整后的权重。critic的输入也是$state$，输出一个分数用于训练actor。\n不过文章中作者并不是直接将所有的链路上的流量信息作为$state$，而是将所有链路的信息先输入一个RNN网络(文中使用的是GRU)，利用RNN来提取整个网络的流量特征，并以这个流量特征作为actor和critic的输入，也就是状态$state$。\n对于为什么要使用RNN，原文中说的比较含糊，我认为是为了适应不同结构的网络。由于网络有大有小结构也不尽相同，如果直接输入DRL，那么训练的模型就只能适用于某个特定的网络。所以通过利用RNN输入个数不限的特点来提取不同结构的网络的流量特征。 疑问🤔️ # RNN最后的一次输入对输出的影响最大，也就是越靠后的输入的重要性越大。而实际中每个链路可以看作是平等的，但并没有实验来说明这个问题 随着网络的增大，会不会RNN提取到的特征也太小，导致没有足够的输入信息来实现一个比较精细的控制 ","date":"7 March 2022","permalink":"/posts/paperreading/scaledrl/","section":"Posts","summary":"文章背景 # 目前的流量工程中，主要的目标就是降低整个网络中最大的链路利用率，也就是将流量分摊到整个网络中。在目前的基于深度强化学习(DRL)的解决方案中，有一些是调整路由的路径，又一些是调整流量在不同路径上的分割比例。","title":"[Computer Network'21]ScaleDRL: A Scalable Deep Reinforcement Learning Approach for Traffic Engineering in SDN with Pinning Control 阅读笔记"},{"content":" 背景 # 文章的主要目的在于目前的数据中心网络(DCN, Data Center Network)中路由的一些问题。\n分布式路由 # 在大规模的网络架构中网络状态改变而导致的收敛过程非常缓慢；还有就是计算整个巨大的网络的路由是非常困难的。\n中心式路由 # 这里作者以Google的路由方案 Firepath作为对比，在Firepath中controller管理着所有链路状态(LS,link-state)的信息，并保存在一个数据库中(LSDB)，并且主controller和多个备份controller之间会同步该LSDB来保持一致。当LS发生变化的时候，controller会告诉每个switch这个信息，然后每个switch根据这一信息自己再计算一个最短路径(SPF)。但是在这样一个规模比较大的网络中(上万个switch),计算SPF也是需要好几秒中才能完成的。\n解决方案 # 针对上述的问题和DCN的架构特点，作者提出了一些解决方案来让switch对LS变化得意快速响应。例如可以先实现计算出一些路径，然后LS变化的时候将相应的路径的状态进行设置即可，也就无需每次去计算SPF。这是文章的一个核心观点。\nDCN架构 # 文章中使用和Firepath一样的网络架构，如下图所示： 控制上，网络中有多个Master用来管理链路信息，这些Master中有一个Lead和多个Backup，这些Master通过控制面网络(control-plan network)与DCN相连。\n整个DCN网络被分为了三层，从上倒下依次是：\nCore Aggregation(Agg) Top-of-Rack(ToR) 数个Agg和ToR一起构成了一个Pod，每个Pod内部的Agg和ToR完全相连，而每个Agg又会与数个Core相连，并且每个Core会与所有的Pod相连。可以看到整个DCN的架构是比较固定的，也有层次化的结构。因此可以不需要像一般的网络那样去计算SPF，因为SPF比较适合架构不一定的网络，面对那样的网络时SPF可以很灵活，但是在这种DCN里面是不需要这种灵活性的。\n方案细节 # Path Table # 由于DCN结构比较固定，每个switch可以事先计算出自己到其他所有switch的路径。\n上表以switch1.1为例，使用 上图架构。表中记录了从1.1到不同的switch的所有路径。\nNo. 代表的是该路径的编号，下个表中会使用到 Next 下一跳的节点 Dest 目的地switch FL failure link 代表这个路径中有多少条link是失效的。 可以看到路径是比较固定的，遵循的是先上后下，先从switch到Core，再从Core到目的地。\n也就不会出现1.1 -\u0026gt; 1.9801 -\u0026gt; 1.9901这样复杂的路径。\nLink Table # switch内部的第二个就是DCN中所有链路的状态表。\nFrom To State Type First Entry From 和 To 代表的链路的方向，之前说过路径是遵循的是先上后下的方式所以有方向。（此处仅对于switch 1.1而言，对于其他的switch，同一条链路可以是2.1 -\u0026gt; 1.1）\nType 代表的是链路的类型（例子中针对switch 1.1而言），由于是先上后下的方式，Type 1 就是 ToR -\u0026gt; Agg, Type 2是Agg -\u0026gt; Core, Type 3是Core -\u0026gt; Agg, Type 4是Agg -\u0026gt; ToR.记录Type的好处就是在链路失效的时候可以直接计算出来所影响的路径的数目。并且由于记录了First Entry，我们可以直接找到受影响的这些路径在 Path Table中的第一条的位置。由于DCN架构是固定的，这些可以在一开始的时候就计算出来。\n处理链路失效 # 当某条链路失效的时候，通过Link Table可以快速计算出有多少条Path会受到影响，并且可以知道第一条路径的编号，例如39601。然后在Path Table中，把39601以及其后若干条路径的FL值+1。\n","date":"4 March 2022","permalink":"/posts/paperreading/primus/","section":"Posts","summary":"背景 # 文章的主要目的在于目前的数据中心网络(DCN, Data Center Network)中路由的一些问题。","title":"[INFOCOM'21]Primus: Fast and Robust Centralized Routing for Large-scale Data Center Networks 阅读笔记"},{"content":"","date":"4 March 2022","permalink":"/categories/routing/","section":"Categories","summary":"","title":"Routing"},{"content":" 文章背景📝 # 多播 vs 单播 (Multicast vs Unicast) # 在某些需要将相同内容发送给多个接收者的时候，例如网络直播或者是视频会议，可以选择传统的一对一方式，把同一份内容分成多分，分别发送给多个接收者，既单播(Unicast)。\n单播方式简单但是有个致命问题就是增加了source节点的带宽开销，而且source节点的带宽并不是无限的，所以能够同时支持的接受者的数目也是有限的。\n另一种方式就是多播，发送者只需要发送一份内容，然后该内容将在不同的节点上进行复制，并转发到不同的路径上，如图所示。 但是对于多播来说也存在一些需要解决的问题，由于接受者在不同的网络位置上，所以发送的包需要在不同的节点处进行复制并转发到不同的端口上。这些操作都需要依赖于查表操作，而硬件能够支持的表项数目也是有限的。 其次，每次多播树发生变化，都要到相应的节点上进行更新操作费时费力。\n解决思路💡 # 这种解决思路有点类似于段路由 Segment Routing的方式。在段路由中，如何进行转发的信息是封装在包头中，而不是由中间节点来决定，中间节点只需要按照分装的转发信息进行转发即可。\n该文章中作者提出了类似的思路，也就是说将多播树的信息分装在包头中，中间的交换机按照相应的方式转发即可。使用这种方式，交换机大部分的情况下只需要查询包头中的多播树的信息即可，并且在多播树发生改变的时候，只需要改变包头中的信息，非常的方便。\n这种方式也产生了一些新的需要解决的问题：\n包头的大小有限，其中的信息应该尽可能紧凑 交换机需要在线性时间内解析这些信息 这种方法也就限制了能够适用的情形，因为无法将整个公共网络的多播树信息全部编码。所以，目前只能适用于数据中心这样的特殊环境之中。\n在数据中心中，所有的节点处于一种树状的层级结构中，由内而为依次是：\nCore Spine Leaf 并且可以把不同交换机看作一个整体，例如所有的Core层级的交换机(C1, C2 \u0026hellip;)就是一个整体，不同的Spine层级的也组成了一个整体（S0, S1 组成为一个Pod 0）。这样的好处就是可以简化转发的策略，S0 和 S1可以使用一样的策略。\n实现🔧 # 在实现中，首先需要调用controller的API，controller计算出了多播树以后再计算出相应的转发策略(rules)，其中p-rules发送给Hypervisor, 而Hypervisor的工作就是把sender发送的包的头部添加上p-rules。 然后controller会把s-rules更新到对应的交换机上，s-rules的作用是一些无法放在包头中的转发规则。 整个包头的信息中分为了5个部分：\nupstream leaf upstream spine downstream core downstream spine downstream leaf 其中的内容都是bitmap，也就是0和1，1就代表转发到对应的端口。以文章中Ha发送的packet的例子来说明这个过程： Ha发送的packet中， u-leaf = 01|M，此时Leaf层级的交换机L0看到以后转发到自己的第二个端口，也就是Hb。 而M是标志位，代表Multipath，也就是要多路径的方式转发给L0的上层P0的两个交换机S0和S1。S0和S1检测到 u-spine=00|M，也就是说不需要向下层转发，只需要向上层转发给C(包含C0,C1,C2,C3).C中的交换机又查看 d-core = 0011，于是转发给最后的两个端口，也就是P2和P3.然后P2根据自己的id，在d-spine查找到 01:[P2]，说明P2需要转发给自己的第二个端口，也就是L5.同样L5查找 d-leaf 找到 10:[L5]，于是L5转发给自己的第一个端口，也就是Hk。\n由于多播树是一个树状的结构，因此向上转发的路径比较固定。而向下转发的节点很多，所以d-spine 和 d-leaf的大小不固定，交换机需要自己挨个查询。\n计算p-rule # 之前已经讲过，p-rule是放在包头当中的转发策略，因此需要提前进行计算。理想情况下，只需要计算出整个多播树，那么就可以确定每个节点该转发给哪些端口。但是如果多播树比较大，那么就不能在有限的空间中塞下真个p-rule。因此作者提出需要进行聚合(Clustering)，也就是让不同的交换机使用相同的一个rule。例如 P0的rule是 011011，P1是011110，那么由于二者相近，可以让P0和P1用相同的rule，具体方法就是把两个rule进行「或」操作 011111 = 011011 | 011110。这样的话计算的结果虽然有一些错误，但是可以大大的节省空间。\n","date":"25 February 2022","permalink":"/posts/paperreading/elmo/","section":"Posts","summary":"文章背景📝 # 多播 vs 单播 (Multicast vs Unicast) # 在某些需要将相同内容发送给多个接收者的时候，例如网络直播或者是视频会议，可以选择传统的一对一方式，把同一份内容分成多分，分别发送给多个接收者，既单播(Unicast)。","title":"[TON'20] Elmo: Source Routed Multicast for Public Clouds 阅读笔记"},{"content":"","date":"25 February 2022","permalink":"/categories/multicast/","section":"Categories","summary":"","title":"Multicast"},{"content":" 📝文章背景 # 跟 SRID中的情形类似，我们需要在网络的一些路由器中启用段路由的功能来实现流量工程(Traffic Engineering,TE)，也就是将链路的负荷在整个网络中进行分担。\n🚒实现方法 # 这篇文章的实现方法分成两个大的部分，一部分是OSPF的权重调节(Weight Adjustment, WA)，并在一部分的节点上启用SRv6，另一部分关于流分配在哪些path上，也需要决定每个path上分配多少比例的流量。\n离线训练 # 🎛️ 调整OSPF权重 # 在WA阶段中，作者使用强化学习算法 DDPG来根据不同的情况动态调整OSPF中的权重。首先需要有策略函数$a_t = \\mu(s_t|\\theta^\\mu)$，策略函数以网络的状态为输入，而输出就是固定长度的向量，这个向量代表了OSPF网络中新的权重。然后再将$s_t$和$a_t$合并在一起，作为Q函数的输入，而Q函数的输出就是对奖励$r_t$的预测值。通过将现在的状态$s_t$和状态$a_t$拿去跟环境交互，就可以得到新的状态$s_{t+1}$和新状态下最大的拥塞程度$U_{max}(S_{t+1})$,通过拿新的拥塞程度和最开始的拥塞程度作比较来判断出动作的好坏，也就能对奖励进行量化。 $$\\alpha=\\frac{U_{max}(S_{1})}{U_{max}(S_{t+1})}$$\n$r_t$与$\\alpha$的关系如图所示 从函数图就可以看出，只要$U_{max}$降低了就可以获得很高的奖励。 现在使用DQN算法就可以去训练神经网络。\n选择SR节点 # 作者介绍了三种选择SR节点的方法：节点度数$DEG(v)$， 中介中心度（Betweenness centrality），负载最重链路（Most Loaded Link,MLL）。通过实验确定MLL方法选择的结果比较好。也就是说根据流量矩阵(包含流的源，目的，以及大小)把出口流量占链路容量最大的节点选成SR节点。\n在线计算 # 计算路径 # 在确定了SR节点以后，我们需要计算几条路径，以后流就会被分配在这几条路径上。感觉作者的这个方法还是比较有借鉴意义的。 网络拓扑 根据 段路由的实现方式，一次路由过程可以分成三个阶段\n源节点 -\u0026gt; 段路由器 段路由器 -\u0026gt; 段路由器 段路由器 -\u0026gt; 目的节点 其中第一个和第三个节点是最短路径路由，而且段路由之间也是最短路径。 可以根据这三个阶段，把这三个阶段可能的所有(源节点, 目的节点)列出来。例如第一阶段就是A到H的最短路径中，可能遇到B和D。而第二个阶段就是段路由器之间的两两组合，第三个阶段是所有段路由器到H的组合。\n不同阶段节点的组合 现在可以认为整个网络图被简化为了只有 源节点，目的节点，SR节点的新图。新图中的节点的距离就是这两个节点在原图中对应的节点之间的最短路径。很容易根据这些信息计算出几条路径。计算出来的路径都是经过了三个阶段的路径，而不仅是指按照最短距离计算出来的路径。这样做就相当于强制流去绕路，以此来缓解链路压力。 计算的路径 值得注意的是$P_4$是不使用段路由的路径。\n分配流量比例 # 在确定好了每个流候选的路径以后，就可以把各种限制条件列成线性规划问题，然后利用; 求解器求解即可。\n$$\\min U_{max} $$ $$\\sum_{p\\in {P_{l}}}f_{l}(p)\\ge 1\\quad {l\\in {L}} $$ $$\\sum_{l=1}^{L}\\sum_{p\\in {P_{l}}}\\sum_{s\\in {S_{p}}}f_{l}(p)\\cdot {I_{s,e}}\\cdot {d(l)}\\le {U}_{max}\\cdot {c(e)}\\quad \\forall {e\\in {E}} $$ $$ 0\\le {f_{l}(p)}\\le 1\\quad \\forall {l\\in {L},p\\in {P_{l}}}$$\n$f_{l}(p)$就是流$l$在候选路径$p\\in {P_{l}}$上的分配情况(至于为什么加起来不等于1，我理解的是可能有冗余)。 $I_{s,e}$ 代表$e$是否属于路径$s$, $d(l)$则是流$l$的需求量，$c(e)$是链路的容量。\n第一个式子是优化目标，也就是让链路最大负载尽量低，第二个是保证流可以全部被正确的路由，第三个是各个链路的使用率的限制，第四个是分配比例的实际含义。\n通过解这个线性规划问题，就可以得到一个很好的分配比例。\n💡总结 # 本文算法分成两部分，一部分是利用DRL来调整OSPF权重，并选择哪些节点部署SRv6。另一部分是在线的情况下计算流的路径和每条路径上的分配比例。\n","date":"6 December 2021","permalink":"/posts/paperreading/wa-srte/","section":"Posts","summary":"📝文章背景 # 跟 SRID中的情形类似，我们需要在网络的一些路由器中启用段路由的功能来实现流量工程(Traffic Engineering,TE)，也就是将链路的负荷在整个网络中进行分担。","title":"(TON'20)Traffic Engineering in Partially Deployed Segment Routing Over IPv6 Network With Deep Reinforcement Learning 阅读笔记"},{"content":"","date":"6 December 2021","permalink":"/categories/srv6/","section":"Categories","summary":"","title":"SRv6"},{"content":" 📝文章背景 # 目前，对于一些单位来说，如果要连接不同地区的网络一般有几个方法。一是租用专线，这样比较安全也比较贵。二是用 MPLS来建立VPN，但MPLS需要保存大量的信息。再者就是用IPSec来进行封装，但是不支持流量工程(在不同路径上分配流量，以避免某些链路过于拥塞)。 Fig. 1. MPLS的路由示意\n在一般的IP的路由方式中，每个包到达了一个路由器以后，路由器会检查其中的IP地址，查询路由表并进行转发。而MPLS则是事先确定好一条路径，而每个MPLS包的链路层header和IP层header之间有个label，MPLS路由器查询到这个label之后就直接往对应路径的下个路由器转发。没有查询IP地址的过程。但MPLS路由器可能需要保存很多流的信息。\n文章指出可以在 SRv6（Segment Routing v6）的基础上来实现流量工程。SRv6是在IPv6的基础上实现的，它会在IPv6的头部里塞入一些路由信息，这些信息将路径分段（segment），每个段都有一个必须要经过的路由器。 Fig. 2. SRv6的路由过程\n一个包从节点1出发，通过第一个段到达节点4，但是怎么到4不做要求，可能是通过多条不同的最短的路径到达（这个过程中IPv6的目的地址已经改成了节点4的地址，所以中间的路由器即使不支持SRv6，就简单地按照IPv6的路由方式工作即可）。然后第二个段是从节点4经过节点5到达节点6.\n这个过程就好比从北京导航去深圳，以前是直接由地图APP来规划，而现在在北京和深圳的中间加了几个必须经过的地方，比如成都和武汉。\n从SRv6的工作方式也可以看出来，要使用SRv6的功能其实也不需要整个网络中都支持SRv6，所以就必须要涉及将某些路由器升级为SRv6的问题。\n🤔核心问题 # 文章的核心问题就是在给出了候选路由器和要升级的路由器数目的情况下，决定将哪些路由器进行升级可以让整个网络的最大使用率尽可能低。\n🛰️模型 # 在该文章中，作者使用的是2-segment routing，也就是一共两个段，且只有一个中间节点。这样的方式可以让算法实现尽量简单，并且作者也声称用2-segment 和 n-segment的差距不大。\n🧮贪婪算法 # 假设现在我们有很多个流 ${f_1,f_2 \\cdots f_m}$，也有很多的候选路由器${O_1,O_2 \\cdots O_l}$(其中$O_0$代表的是不使用SR，而是直接按照传统的路由转发方式)。\n那么，我们现在就需要决定把某个流经过哪个路由器的段路由比较合适。为了方便理解，文章中使用下面这个类似于“全连接”的图来进行讲解。\nFig. 3. m个流对 l + 1 个路由器可能的选择\n在2-segment的路由中，对于一个流$f_i$，我们需要指定一个段路由器$O_k$，然后$f_i$从自己的源节点$s_i$通过多条不同的最短路径(Shortest Path)到达$O_k$，然后再通过多条不同的最短路径到达流的目的节点$d_i$。在这个过程中可能会使用网络中的多条链路，并提高这些链路的利用率。\n这个利用率的提高幅度(百分比)用向量$\\vec{u_{ik}}$表示。这个计算过程比较复杂，就不再赘述了。在得到$\\vec{u_{ik}}$以后，我们就可以在这个全联接网络中来进行挑选，挑选的原则是贪婪原则，也就是保证每次增加的最大利用率最少。\nFig. 4. 贪婪算法例子\n在这里我们用 无穷范数表示向量分量的最大值。例如${\\lVert\\vec{u_{11}}\\rVert}_\\infty = 4$,${\\lVert\\vec{u_{12}}\\rVert}_\\infty = 5$\n第一步，可以认为总的利用率为$[0,0,0]$选择最大利用率的$\\vec{u}$, 可以看到无穷范数最小的几个向量$\\vec{u_{11}}$,$\\vec{u_{22}}$,$\\vec{u_{32}}$,$\\vec{u_{33}}$ 的无穷范数都是4，那么这里就选择$\\vec{u_{11}}$。此时我们已经确定了流$f_1$用到$O_1$的段路由，那么它就不会用其他节点的段路由，因此后续就不再考虑$\\vec{u_{12}}$和$\\vec{u_{13}}$。\n第二步，现在的利用率是$[3,4,2]$，由于${\\lVert\\vec{u_{11}} +\\vec{u_{22}} \\rVert}_\\infty = 7$ 比其他的组合情况所增加的范数小，也就意味着在这样的选择情况下网络中所有链路的最大利用率比较小，\n第三步，按照同样的思路，尽量让增加的范数小，因此选择了$\\vec{u_{32}}$，因为${\\lVert\\vec{u_{11}} +\\vec{u_{22}} +\\vec{u_{32}} \\rVert}_\\infty = 11$。\n可以看到贪婪算法每次只考虑那一次选择的时候，范数的增加尽量的少，但是这样可能导致最终的结果并不是最好的，例如${\\lVert\\vec{u_{11}} +\\vec{u_{21}} +\\vec{u_{33}} \\rVert}_\\infty = 9$，这样的组合有更小的链路最大利用率。\n所以这了尽量得到更好的结果，作者尝试使用强化学习的方法，让AI自己来选择怎么去组合。\n🤖强化学习方法 # 在强化学习中，我们需要将面临的环境作为输入放到DRL网络中进行学习。但是这样做有一个问题，由于各个网络拓扑的不同，流和候选路由器的数目也不同，造成状态空间大小的不同（可以理解为输入DRL的参数数目不同），我们没法使用一个DRL来应对所有的问题。\n因此作者在本文中，将环境状态也就是图3 中的Graph进行了Graph Embedding，得到了一个d维向量，这个向量包含了Graph的一些特征。（这里的d是一个超参数）\n作者特征提取的表达式如下\n$${\\tilde{\\mu}}_{ik} = \\sigma(W_1x_{ik}+W_2 \\sum_{e_{uv}\\in N(e_{ik})}{\\tilde{\\mu}}_{uv}+W_3\\lVert \\sum_{e_{uv}\\in N(e_{ik})}{\\vec{u}}_{uv}\\rVert_\\infty)$$\n这个比较复杂，可以不用尝试去理解……\n${\\tilde{\\mu}}_{ik}$ 是一个d维的向量，代表链路$e_{ik}$的某些特征。$N(e_{ik})$代表$e_{ik}$的邻居。$\\sigma$代表ReLU函数。而$W$在文中的作用作者写的很含糊，但是根据后文中的DQN公式，我画出了如下的图。\nFig. 5. 公式对应的结构图\n蓝色的就是$W_1$一个1xd的结构，共色是$W_2$是个dxd结构,$W_3$是个1xd的结构。但这个公式并不是一个神经网络，而是一个迭代的算法，由于每一轮计算的时候都带有邻居的一些信息，所以经过很多轮以后的到的${\\tilde{\\mu}}$就包含了整个Graph的一些信息，后文会用这些特征作为DRL的状态输入$state$。但是作者也没有细说这些$W$是怎么来的。\n🔮状态state # DRL的状态$\\phi(S)$就是以上面的特征为基础的一个d维的向量。\n💶奖励reward # 回到贪婪算法的部分，我们希望的是选取的边对应的$\\vec{u}_{ik}$的和的无穷范数最小，所以应该这样评价现在状态的好坏(下面的公式经过简化)：\n$$c(\\phi(S_t))=-\\lVert \\sum \\vec{u}_{ik}\\rVert_\\infty$$\n而奖励就是状态好坏的变化\n$$r(\\phi(S_t))=c(\\phi(S_t+1))-c(\\phi(S_t))$$\n可以看出总体思路还是和贪婪算法差不多的，让最大使用率的提升尽量的少。只不过在DRL中可以使用折扣系数$\\gamma$，让AI多考虑点未来长远的情况。\n💡Q-learing # Q-value的计算公式如下\n$$Q(\\phi(S),a_{x_{ik}=1})=W_5\\sigma([W_6\\phi(S),W_7{\\tilde{\\mu}}_{ik}])$$ 按照上文的分析，这其实就是一个全连接网络的表达方式。只不过和一般的Q-learing还不太一样，一般的Q-learing都有固定神经元数目的输出层，直接可以一次性比较所有动作的Q-value。而作者的方式是只输出一个Q-value。\n在实际过程中,需要对每一条边都进行一次Q值的计算，也就是把上文中Graph Embedding 得到的$\\phi(S)$和${\\tilde{\\mu}}_{ik}$ 仍进一个全连接网络，计算到Q-value，选后选取Q-value最高的$e_{ik}$。这个时候网络状况改变，就再做一次Graph Embedding提取特征，然后再来计算Q-value……\nFig. 6. 通过DRL选择路由器的过程\n🚧其他 # 除了这些以外，作者还用到了一些常用的DQN技术，比如说replay buffer来增加训练数据的无关系。比如多用一个Target网络来增加训练的稳定性等。\n🎉总结 # 本文中关注于如何在一堆的路由器中挑选一些路由器来进行升级。比较新颖的是作者将问题抽象成流flow和候选路由器的组合问题。并通过贪婪算法和DRL两种方法来进行优化。在DRL算法中，为了应对不同的组合情况，作者使用了Graph Embedding的方法将不同的情况提取成d维的特征，方便了DRL网络的学习。\n","date":"2 December 2021","permalink":"/posts/paperreading/srid/","section":"Posts","summary":"📝文章背景 # 目前，对于一些单位来说，如果要连接不同地区的网络一般有几个方法。一是租用专线，这样比较安全也比较贵。二是用 MPLS来建立VPN，但MPLS需要保存大量的信息。再者就是用IPSec来进行封装，但是不支持流量工程(在不同路径上分配流量，以避免某些链路过于拥塞)。 Fig.","title":"(TON'21)Optimal Deployment of SRv6 to Enable Network Interconnection Service阅读笔记"},{"content":" 网络相关 # 术语 中文 白话 flow 流 逻辑上一个节点到另一个节点的流 traffic 流量 流量 path 路径 一个节点到另一节点之间经过很多其他节点构成的路径 traffic engineering 流量工程 如何去控制不同路径之间的流量分配，减少流量对某些链路的压力 link 链路 两个相邻节点之间逻辑上的\u0026quot;网线\u0026quot; load balancing 负载均衡 让流量在从源节点到目的节点的多条路径中分配，减少链路压力 packet switching 分组交换 把一个大的包拆成小包，每个小包按照相同或者不同的路径被送到目的地 circuit switching 电路交换 整个包按照固定的路径被送到目的地 Multiprotocal Label Switching( MPLS) 多协议标签交换 在L2层的header和L3层的header之间插入一个标签，路由器只检查这个标签并按照预定的路径来路由。也就不需要再检查L3层中的IP地址和路由表 Label-swiched Path(LSP) 标签交换路径 MPLS中预先确定好的路径 Segment Routing 段路由 MPLS中每个节点都要保存对应label的路径信息，新的label就要记住新的信息。而SR则是每个包自己保存了一些分段的信息，每到一个节点，节点根据包里面的信息转发给下一个段。 stretch 弹性？ 实际选择的路径与最佳路径之间的差距 oblivious 网络当中，路径的选择与当前网络的状况有关，参见 PDF MaxFlow 最大流问题 由于网络中有不同容量的链路，某些链路可能是瓶颈链路。最大流问题就是寻找能从源节点到目的节点的路径，是通过的流量最大 图相关 # 术语 中文 白话 graph 图 把整个网络的结构看成是数据结构中的图 vertex 顶点 在网络中代表的就是节点 edge 边 在网络中代表的就是链路 centrality 中心度 图中任意两个节点之间最短路径经过某条 边/节点 的次数。表明了这条 边/节点 在图中的重要性 Shortest Path First( SPF) 最短路径优先 寻找图中两个节点之间最短路径的方法 ","date":"11 November 2021","permalink":"/posts/transnetwork/","section":"Posts","summary":" 网络相关 # 术语 中文 白话 flow 流 逻辑上一个节点到另一个节点的流 traffic 流量 流量 path 路径 一个节点到另一节点之间经过很多其他节点构成的路径 traffic engineering 流量工程 如何去控制不同路径之间的流量分配，减少流量对某些链路的压力 link 链路 两个相邻节点之间逻辑上的\u0026quot;网线\u0026quot; load balancing 负载均衡 让流量在从源节点到目的节点的多条路径中分配，减少链路压力 packet switching 分组交换 把一个大的包拆成小包，每个小包按照相同或者不同的路径被送到目的地 circuit switching 电路交换 整个包按照固定的路径被送到目的地 Multiprotocal Label Switching( MPLS) 多协议标签交换 在L2层的header和L3层的header之间插入一个标签，路由器只检查这个标签并按照预定的路径来路由。也就不需要再检查L3层中的IP地址和路由表 Label-swiched Path(LSP) 标签交换路径 MPLS中预先确定好的路径 Segment Routing 段路由 MPLS中每个节点都要保存对应label的路径信息，新的label就要记住新的信息。而SR则是每个包自己保存了一些分段的信息，每到一个节点，节点根据包里面的信息转发给下一个段。 stretch 弹性？ 实际选择的路径与最佳路径之间的差距 oblivious 网络当中，路径的选择与当前网络的状况有关，参见 PDF MaxFlow 最大流问题 由于网络中有不同容量的链路，某些链路可能是瓶颈链路。最大流问题就是寻找能从源节点到目的节点的路径，是通过的流量最大 图相关 # 术语 中文 白话 graph 图 把整个网络的结构看成是数据结构中的图 vertex 顶点 在网络中代表的就是节点 edge 边 在网络中代表的就是链路 centrality 中心度 图中任意两个节点之间最短路径经过某条 边/节点 的次数。表明了这条 边/节点 在图中的重要性 Shortest Path First( SPF) 最短路径优先 寻找图中两个节点之间最短路径的方法 ","title":"计算机网络领域的英文白话对照"},{"content":" 针对的问题 # 在传统的网络路由的算法中，路由对flow的处理方式通常是基于最短的跳数或者是链路的权重来计算如何路由，但是这种方式并不能对不同类型的flow进行区别对待。在 DRL-OR文章中，作者提出了4种基本的flow的类型，如下所示。\n服务类型 典型应用 latency-sensitive 上网 throughput-sensitive 下文件 latency-throughput-sensitive 视频直播 latency-loss-sensitive 打游戏 文章认为应该分别对每种类型的flow有针对性的处理，否则就会出现如下图所示的情形。 第一个flow是由S-\u0026gt;T，它直接占据了Router1和Router3之间的所有带宽。导致第二个S\u0026rsquo;-\u0026gt;T的latency-sensitive 的flow不得不去绕路，导致时延增加。文章希望通过深度强化学习(DRL)的方式来让AI自动学习如何去规划每个flow的路径(path)。\n强化学习模型 # 文章中采用PPO算法来实现，主要是考虑到PPO比较有效率，并且训练的方差比较小，训练过程可以更加稳定。 上图是文章中的神经网络，中间层是64*64的全连接层。输出层非常的特别，采用了一种非常冗余的方式，它计算了所有的目标节点，所有的服务类型，所有的action的概率。文章中给的图会有一点误导性，会让人感觉输出的神经元是全部并列在一起的，但实际上这些输出的神经元是“叠起来”的。假如有$V$个节点，有$T$个类型，有$A$个action。就会有$VT$个小网路，每个小网络都是是 $64 \\cdot A$的结构（64是隐藏层的神经元个数），并且全部接在前面的隐藏层后面。\n在这个网络中，action的数目就是一个节点的邻居数目，也就是转发的时候可以的选择个数。而且一个agent有一个自己的网络（上图代表的一整个网络）。\n之所以采用这样冗余的做法，按照文章中作者的说法是，这样做有很好的灵活性，如果有新的节点或者是service type，就只需要加几个网络跟隐藏层连接在一起，以前已经训练好的网络不受影响(并不认同)。\n在agent计算下一跳的时候，首先把整个$state$喂到DNN里面，然后计算所有的概率，最后根据目的节点和该flow选到对应的网络，再在这个网络输出的$A$个值里面采样（某一个action的值越大越容易被选中）。\n状态state # 每个agent由于自己情况的不同，所对应的state space 和 action space都是不同的，DNN的结构也有些不同。\n所有agent共用的部分 # 所有链路剩余容量、所有链路丢包率：由于所有链路用$|V|*|V|$的矩阵表示，所以链路剩余容量和丢包率矩阵的大小都是$|V|^2$。\nagent之间不同的部分 # 每个邻居到其他节点的最大容量：这个记录了一个节点的邻居到网络中所有节点的最大容量(从一个节点到另一个节点的所有路径中，容量最大的路径的容量)，大小是$|V| \\cdot |N|$，其中$|N|$是这个节点邻居的数目。\n每个邻居到其他节点的距离：每个邻居到所有节点的距离（跳数hop），大小$|V| \\cdot |N|$\none-hot vector：包含源节点、目的节点、flow类型的one-hot。大小 $2|V|+|T|$，$|T|$是service type的数目。 (one-hot就是一个向量，其中只有一个元素是1，其他的都是0。比如一共有3个节点，我想代表2号节点，对应的向量就是$[0,0,1]$)\ncondition state：这是一个向量，内容要么是0，要么是1.如果某一个位置上是1，就代表之前已经有一个对应的agent被加到了path中，后文中将结合代码实现讨论。\n动作action # action space就是每个agent的邻居的数目，根据agent选择的action，把flow转发给对应的邻居。\n奖励reward # 由于每种类型的需求不同，为了让DRL更好的服务不同类型的flow，需要根据类型的不同来使用不同的奖励函数。奖励函数的定义如下：\n$U_t=w_1log x_t - w_2y_t^{\\alpha _1}- w_3z_t^{\\alpha _2}$\n其中$x_t$是吞吐量，$y_t$是延时，$z_t$是丢包率。为了让这些指标到一个数量级，使用$log(\\cdot)$和$(\\cdot)^\\alpha$来处理数据。$w$是不同指标的权重，有以下的设置。\n服务类型 典型应用 $w_1$ $w_2$ $w_3$ latency-sensitive 上网 0 1 0 throughput-sensitive 下文件 1 0 0 latency-throughput-sensitive 视频直播 0.5 0.5 0 latency-loss-sensitive 打游戏 0 0.5 0.5 PPO算法 # 在DRL-OR中，每个agent都有自己的模型，而且并不是每个agent都在规划的path上面，如果不在path上就不应该得到奖励。目标函数：\n$J(\\theta)^{CLIP} =\\Bbb E_{\\tau\\sim p_{\\theta^i_{old}}(\\tau)}[m^i \\cdot min(A(s,\\textbf{a})r(\\theta ^i),A(s,\\textbf{a})r\u0026rsquo;(\\theta ^i) )]$\n如果agent在path上，${m^i}$为1，否则是0. 其中$r(\\theta ^i)$是新旧两个$\\pi$函数预测值的比值，是一个比值构成的向量。为了让预测更加稳定，PPO对$r(\\theta ^i)$进行了裁剪得到$r\u0026rsquo;(\\theta ^i)$，也就是限制在$(1-\\epsilon,1+\\epsilon)$之间，这样更新幅度就不会太大。$A(s,\\textbf{a})$是PPO中的一个advantage fuction，跟奖励reward有关，并反映了action的好坏，详见 PPO论文.\n算法实现 # 算法部分参照DRL-OR的 开源代码。\n算法中包含五个主要进程。testbed、ryu-controller、drl-or、client、server。\n其中drl-or是算法部分的实现，在drl-or中会根据配置生成flow的请求（包含一个flow的很多信息），然后把计算的flow发送给testbed，计算的path发送给ryu-controller。 testbed是基于 mininet的一个程序，testbed根据事先配置的拓扑结构来模拟一些host和switch。在收到生成的flow请求后，testbed会开启client进程和server进程，client进程负责按照flow的要求来向server进程按照一定的速度发送一定时间的flow。server进程负责统计实际收到的吞吐量、时延、丢包率，并在进程结束的时候返回给testbed。testbed中的switch的控制机制是在ryu-controller中实现的，每次testbed中的switch收到一个包，都要去问ryu-controller往哪儿转发，后者根据path信息，确定转发的方向。\n实现细节 # drl-or进程启动的时候回去读取拓扑配置文件，配置文件中定义了网络中的节点和链路的信息，还有任意两个节点之间的发包权重。drl-or根据这些权重来随机生成任意两个节点之间的flow（权重越高，生成的几率越高），这个flow可能是任意的service type。此时生成的flow的src,dst,type,duration（持续时间）是确定的。我们需要计算这个flow是按照怎样的路径从src到dst。\n这里有一个特殊的向量condition state，它标记了哪些agent已经被加到了path之中，相当于让agent偷看到了其他agent的选择。condition state中的元素要么是0，要么是1。如果是1，就代表对应的那个agent已经被加到了path中。\n从src节点开始，计算$state$,由于src是path中的第一个节点，所以src看到的condition state 是$[0,0\\cdots 0]$全0的。将$state$+condition state喂给actor-critic，actor将计算出对应的action，critic也将计算出value，这个value是对奖励的预测，用在PPO算法中。\n由于src确定了action，那么path中就已经有了src节点了，同时第二个节点也就确定了。同样的，也为第二个节点计算$state$和condition state，由于src已经在path中，那么第二个节点看到的condition state就是 $[0,0\\cdots 0,1,0\\cdots0]$,那个1对应的就是src的节点。\n重复上面的步骤，直到path达到dst节点或者出现了环。要知道这个path是DRL生成的，有可能根本就是随机的，所以算法需要检查path是否合法，例如有环、超出链路剩余容量等。如果path有问题，算法就会再生成一个新的path，这个新path是按照图的方法来计算出来的。这个时候，前文中计算的节点之间的跳数还有节点之间的最大容量就被用来计算新的path。\n这个时候一个flow需要的一切都准备好了，drl-or进程把flow的src,dst,src_port,dst_port,path发送给ryu-controller，ryu-controller会在交换机中进行设置，当交换机遇到这个flow的时候就会按照path的要求，往对应的节点转发。同时drl-or将src,dst,src_port,dst_port,type,demand（发送速率）,time（持续时间）发送给testbed，testbed开启client进程来发送TCP包，同时开启server进程来接收TCP包。\nserver进程会统计包的吞吐量、时延、丢包率，并通过管道返回给testbed，server的统计结果会在运行过程中隔一段时间就返回一次，但是testbed只care一次的结果。testbed在收到统计结果后就将统计结果发送给drl-or。此后的testbed会在时间到了以后将client和server进程杀掉。所以也就是说testbed即使返回了统计结果，这个结果也只是一段时间内的统计结果，并不是最终的统计结果。而且即使返回了统计结果，client和server也是还在运行着的。\ndrl-or收到统计结果后，按照上文中的函数来计算奖励reward。但这个时候不会立即更新actor-critic模型，而是将所有的state,action,reward,next_state,value，condition state保存在一个replay buffer中。在一段时间以后将这个replay buffer中的数据随机(消除数据之间的相关性)取一些出来，然后交给PPO算法来学习，并更新actor-critic模型。\n下图是算法实现的一些模块之间的调用关系。\n（新窗口看大图）\n","date":"10 November 2021","permalink":"/posts/paperreading/drlor/","section":"Posts","summary":"针对的问题 # 在传统的网络路由的算法中，路由对flow的处理方式通常是基于最短的跳数或者是链路的权重来计算如何路由，但是这种方式并不能对不同类型的flow进行区别对待。在 DRL-OR文章中，作者提出了4种基本的flow的类型，如下所示。","title":"(INFOCOM'21)DRL-OR: Deep Reinforcement Learning-based Online Routing for Multi-type Service Requirements 阅读笔记"},{"content":"","date":"10 November 2021","permalink":"/categories/ppo/","section":"Categories","summary":"","title":"PPO"},{"content":" 基本思路 # 在现在的基于深度强化学习(Deep Reinforcement Learning,DRL)模型的流量工程(Traffic Engineering,TE)中，我们需要让AI来学习网络中的某些特征，并实现对网络中的流量有一个合理的调度,让整个网络的总体有个好的性能。 文章通过DRL来学习如何让flow在不同的路径(path)中有一个合理的分配比例，从而提高网络性能。\n解决痛点 # 假设一个网络中有N个节点，和一个controller，那么，不管是节点之间的路径计算还是稍后的流量分配，都会有个$O(N^2)$的开销。这样的话随着节点数目的增大，计算本身的开销也会增大很多。\n另外让一个controller来控制整个网络，本身就会面临单节点挂掉的风险。所以该文中使用的方法是一个在域(region)这个级别来管理流量。\nDRL模型 # 该文中，把整个网络的状态抽象为一个向量state，然后交给DRL，而DRL的输出action也是一个向量，表示的是如何在不同的path之间来分配这个流量。在网络采用了DRL的建议以后，网络的状况可能变好或者变坏，我们把状况的变化进行量化为reward并反馈给DRL。DRL根据我们的反馈来调整自身神经网络的参数。 如图所示DRL有多个的输出，每个输出就是从节点i到节点j的分配比例（i到j有不只一条实现确定好的path）。\n但如果只是这样做还有个缺陷，有一些流量是会跨region的，所以一个region中的agent(可以理解为DRL模型中观察环境和做决定的实体)的决定也会影响其他的region。所以作者将流量分成2类。一种是terminal traffic，它的目的地就在本region以内。另一种是outgoing traffic，它的目的地不在这个region中。既然要分开处理两种流量，该文中使用两种agent来处理流量。一种是T-agent，专门处理目的地在本region的流量(terminal traffic)。一种是O-agent，专门处理目的地在其他region的流量(outgoing traffic)。\n后续内容将围绕T-agent和O-agent的设计展开。\nT-agent # 大流量和小流量elephant \u0026amp; mice traffic # 由于该算法的目标是把流量给分割。那么对于大流量，这样可以有效降低某条边上的拥塞情况。但是对于小流量，它本身已经很小了，可以认为不管有没有它，对链路的影响也不大。该算法中，先统计从i到j的流量的大小，并排序。然后引入超参数$\\rho \\in [0,1]$，在排序中高于$\\rho$比例的才认为是大流量。比如$\\rho = 0.8$，那么就需要大于80%的流量才算是大流量。而T-agent只管大流量，小流量采用静态路由的方法。\n状态state # state的定义为 $\\textbf{s}_t^{m,T}=[\\frac{f_e}{c_e}]_{e \\in E_m}$ 其中$c_e$是一条边(edge)的容量，$f_e$是已经使用的容量，$E_m$代表region m中的所有边的集合。t代表的是时间。这个$\\textbf{s}_t^{m,T}$就表示了region内的边的状况。\n动作action # 如果算法在收到流量的请求以后才开始计算路径，然后再在这些路径上分配流量。这样做会导致过程过于复杂，可能DRL也难以收敛。\n所以，作者使用的方法是 预先计算K条(经验上，K=3)从节点i到节点j的固定路径。每次T-agent的计算结果就是在这K条路径上的分配比例。\n定义T-agent的输出的action为：\n$\\textbf{a}_t^{m,T}=[a_p^{i,j}]_{p\\in P_{i,j}^m,i\\neq j,i,j \\in V_m}$\n$a_p^{i,j}$就是从节点i到j的某条路径p上的分配比例。很明显 $a_p^{i,j} \\in [0,1]$ 并且 $\\sum_p a_p^{i,j}=1$。$P_{i,j}^m$就是上文中说的那K条从i到j的路径。$i,j \\in V_m$意思是i,j在同一个region。\n把这个公式翻译成中文就是从i到j的流量流量应该按照什么比例来分到各条路径上。\n不过要注意的点是，由于i和j并没有确定，所以$\\textbf{a}_t^{m,T}$包含了整个region中所有的节点与节点之间的分配比例。$\\textbf{a}_t^{m,T}$的大小(action space)是$O(K\\cdot|V_m|^2)$。从这里也能看出，把整个网络分割成多个region也能有效减少action space。\n奖励reward # reward的定义如下：\n$r_t^{m,T}=-1\\cdot \\max_{e \\in E_m}{h(e)}$\n其中h(e)的定义为 $h(e)=\\frac{f_e^{(1+\\alpha)}}{c_e^{(1+\\alpha)}(1+\\alpha)}$\n其中$f_e$是一条边上的总流量，$c_e$是一条边上的总容量。$\\alpha$是超参数。可以看到T-agent的目的就是要降低region内最拥堵的边。\nO-agent # O-agent状态state # $\\textbf{s}_t^{m,O}=[\\frac{f_e}{c_e}]_{e \\in E_m}$\n跟T-agent一样，就是观察自己所在region的拥塞程度。\nO-agent动作action # $\\textbf{a}_t^{m,O}=[a_p^{i,m\u0026rsquo;}]_{p\\in P_{i,j}^m,i\\neq j,i\\in V_m,j\\in Vm,m\u0026rsquo;,m\u0026rsquo;\\in neighbor(m)}$\n其中\n$\\sum_{p\\in P_{i,j}^m,j\\in V_{m,m\u0026rsquo;}} a_p^{i,m\u0026rsquo;}=1$\n$m\u0026rsquo;$是与m相邻的region。\n$V_{m,m\u0026rsquo;}$是两个region m和$m\u0026rsquo;$边界上的节点。 在作者的设计中，从m中的节点i到域$m\u0026rsquo;$有三个节点，每个节点有一条path，每条path依据从节点i到该节点的最短跳数(the smallest hop)计算出来的。\nO-agent的action和T-agent类似，只不过在T-agent中是从节点i到节点j的分配比例。而O-agent是从节点i到域m\u0026rsquo;的路径的分配比例。并且这些路径可能是从不同的边界上的节点到达m\u0026rsquo;域的。类似于你从中国到俄罗斯去，就可以通过好几个口岸出国。\nO-agent奖励reward # 由于一个region内O-agent的活动会影响其他的region，所以除了借鉴T-agent的reward计算方式，O-agent还考虑了自己的region和相邻region的reward。\n$r_t^{m,O}=\\beta\\cdot r_t^{m,T}+(1-\\beta)\\cdot \\textbf{E}_{m\u0026rsquo; \\in neighbot(m)}[r_t^{m\u0026rsquo;,T}]$\n可以看到O-agent的reward就是把自己region和相邻region的T-agent的reward组合在一起。$\\beta$是个超参数。\n总结 # 可以看到文章作者花了很多的功夫来降低算法的开销，比如预先计算path而非实时计算path。或者是以region为单位来控制而不是以整个网络为单位进行控制，这样不仅降低了单节点风险，还提高了算法效率和可扩展性。\n算法亮点 # 分region、预先计算path来降低DRL的输出内容\n","date":"3 November 2021","permalink":"/posts/paperreading/mrte/","section":"Posts","summary":"基本思路 # 在现在的基于深度强化学习(Deep Reinforcement Learning,DRL)模型的流量工程(Traffic Engineering,TE)中，我们需要让AI来学习网络中的某些特征，并实现对网络中的流量有一个合理的调度,让整个网络的总体有个好的性能。 文章通过DRL来学习如何让flow在不同的路径(path)中有一个合理的分配比例，从而提高网络性能。","title":"(ICNP'20) A Multi-agent Reinforcement Learning Perspective on Distributed Traffic Engineering 阅读笔记"},{"content":"","date":"3 November 2021","permalink":"/categories/ddpg/","section":"Categories","summary":"","title":"DDPG"},{"content":" 基本模型 # 在机器学习的大类中，有一类学习过程需要和环境进行互动，在互动的过程中得到环境的反馈，而AI要做的事情就是通过学习来尽可能的得到更好的反馈。比如说让AI玩超级玛丽，在超级玛丽中，AI吃到金币得到好的反馈，碰到蘑菇怪🍄就会得到坏的反馈。而AI要做的就是学习如何看到一个画面的时候作出好的决定。其实过程和人类完游戏也差不多。\nMDP模型 # 当然机器不能直接以人类的方式学习，我们必须通过某种方法对问题建模，通过优化模型的参数来提高模型的效果。在DRL中，使用的基本模型是马尔可夫决策过程(MDP)。 如图所示，图中的绿色圆圈代表的就是状态$state$,它代表整个MDP模型当前所处的状态。我们可以通过采取一些动作$action$来让状态之间是相互转换。在采取了某个动作以后，进入到的下一个状态也是不确定的，有一定的随机性。类比于马里奥中的例子，$state$就相当于我们AI看到的世界，有可能是像人类一样看见画面，也有可能看见的就是一堆描述游戏内状况的数据。而$action$相当于我们可以选择的动作，比如左走、右走、跳跃、什么都不做等。\n奖励 # 由于我们采取了动作，从而导致自身所处的环境变化，所以我们需要从环境中获得反馈，才知道自己所做的行为到底是好还是不好。这个反馈叫做奖励reward,记为$r$或者是$r(s,a)$。我们在作出一个行为以后就可以立即得到reward。在具体实现中，我们可以根据环境的某些属性的变化来量化这个reward，比如吃到金币就+100，死亡就-100，具体也没有一个标准。这部分的内容不在强化学习的内容中。\n但是如果我们只让AI取在乎当前的得失的话，那么AI就可能为了吃一个金币而掉到坑里死掉。所以我们需要让AI变得有远见，要考虑未来的奖励。由于过程的进行，我们的行为的效果会随着时间的推移而变小。类比马里奥中就是我现在跳一下可能会影响未来10秒钟的游戏进程，但对1分钟以后的游戏进程的影响已经微乎其微了。综合考虑，我们需要把未来的奖励reward也用来评判当前的行为。折扣回报公式如下\n$U_t=\\sum_{k=t}^{\\infty}\\gamma^{k-t}r_k$\n策略函数 # 在强化学习中策略函数$\\pi(a|s)$代表的是面对某一个状态$s$时我们采取各个动作的概率（这里的$a$并不是一个数值，而是一个n维的向量，n就是可以采取的action的数目，比如“左”，“右”，“跳”就是三维的action，可能的输出为每个动作对应的概略，例如$[0.1,0.2,0.7]$），比如头上有一个金币的时候就应该倾向于往上跳,所以此时往上跳的概率应该比较大。通过调整策略参数，让好的action有更大的概率，从而获得更多的奖励。\n动作价值函数 # 我们用动作价值函数\\\n$Q_\\pi(s_t,a_t)=E_{S_{t+1},A_{t+1},S_{t+2},A_{t+2},\\dots} [U_t|S_t=s_t,A_t=a_t]$\n动作价值函数评价了当我们面对一个状态$s_t$时作出动作$a_t$这个行为的好坏。通过定义可以看出，我们唯一能确定的就是t时刻的状态和动作，即$S_t=s_t,A_t=a_t$。而评价的方式就看折扣回报的期望。但由于后序时刻的状态和动作都不确定，所以该期望是在随机变量$S_{t+1}$和$A_{t+1}$的基础上确定的。再者，由于action的选取是和策略函数有关，所以Q也和$\\pi$函数有关。\n状态价值函数 # 状态价值函数是对状态打分。在马里奥的例子中，如果都快掉到坑底了，那么这个状态应该是一个比较坏的状态，如果是马上吃到了金币，那这是一个比较好的状态。状态价值函数定义如下\n$V_\\pi(s_t)=E_{A_t,S_{t+1},A_{t+1},S_{t+2},A_{t+2},\\dots}[U_t|S_t=s_t]$\n也就是说在t时刻，能确定的只有目前的状态$s_t$，而具体的action是不知道的，所以对我们的期望来说，t时刻的动作也是一个随机变量，也就是$A_t$。 和上文的$Q_\\pi(s_t,a_t)$相比，期望仅仅是多了一项$A_t$。把$V_\\pi(s_t)$和$Q_\\pi(s_t,a_t)$相比较可以得到以下公式:\n$V_\\pi(s_t)=E_{A_t\\sim\\pi(\\cdot|s_t)}[Q_\\pi(s_t,a_t)]$\n蒙特卡洛方法 # 对于随机变量$X$,我们并不知道它的具体形式，包括期望和方差，也就没法从理论方面来求它的期望和方差。但是根据大数定律，$X$的样本均值$\\frac{1}{n}\\sum_{i=1}^n x_i$在$n \\to \\infty$的情况下会收敛到$X$的期望$E(X)$。通俗一点来说，就像是扔硬币，只要你扔的次数够多，那么得到正面的概率就会越来越趋近于0.5。在MDP中的随机变量是非常复杂的，我们非常难求到期望，我们就可以使用蒙特卡洛方法，暴力重复实验，只要我重复的次数够多，那么我得到的样本的均值就可以趋近于这些复杂的随机变量的期望。蒙特卡洛方法是DRL的灵魂，DRL只要有求期望，那么大概率是由蒙特卡洛方法来暴力趋近。\n价值学习 # 现在我们知道$Q_\\pi(s_t,a_t)$函数可以评价我们的action的好坏，所以如果我们能在每一次在执行动作之前，我们可以计算每个动作的动作价值函数（反正能执行的动作个数是有限的），然后选出能让Q函数最大的那个动作。每次都做最好的动作就可以得到最好的结果。\nDQN算法 # 在状态数目有限的情况下，我们可以通过动态规划来得到Q函数，但很多时候状态是无限个的（例如马里奥和金币的距离: 1, 0.99, 0.98\u0026hellip;.都可以看作是一个状态，状态数目当然是无限多的），所以我们用一个深度神经网络(DNN)来近似Q函数。DNN的输入是面临的状态，输出是多维的，分别对应每个action的动作价值。这个网络就是Deep Q Network(DQN)。\n在DQN中，我们的决策方式是把状态$s_t$输入DQN网络，DQN网络会给每个action打分，我们只是简单的选取得分最高的action。理论上来说只要DQN打分准确，我们就可以开挂，在动作发生之前就预测到了动作的结果。\n回想一下策略函数$\\pi$，他输出每个action被选取的概率，也就是说每个action都是有可能被选到的，这样可以保证我们对每种情况的探索。但是在DQN算法中，我们并不依赖$\\pi$函数，而且每次都是选得分最高的action。这样会导致一个问题，在DQN训练的初期，可能某个实际上不好的action的得分会超过其他的action，那么DQN就会执行这个action，而减少了对其他action的探索。这个道理就像是你去餐馆吃饭，最开始的时候吃了一个好吃的菜，然后你每次都吃这个菜。但由于你没有去尝试其他的菜，所以很有可能你吃到的并不是餐馆里最好吃的菜。\n因此，我们在DQN中加入参数$\\epsilon$（可能是0.05），他是一个很小的值。在实际实现中，我们有$1-\\epsilon$的几率来执行DQN最大值的动作，有$\\epsilon$的概率来执行一个随机的动作，以此来保证对情况的充分探索。而$\\epsilon$也会随着时间推移而减少。\nTD error # 我们可以先玩一把游戏，然后通过计算所有$(s_t,a_t)$对应的$u_t$，然后来训练DQN。但是这样做又一些问题：首先，很多情况下过程并没有结束的状态，例如flappy bird的游戏，只要你足够强，游戏就不会结束。第二点，即使对于可以结束的游戏，也要打完一把才能训练一次，这样的效率过于低下。\n所以我们使用时间查分(Temporal Difference)的方法来解决上述的问题。想想这个例子，你要去上班，出门之前你预测今天需要1个小时。然后当你走到地铁站的时候你预测还需要30分钟。按理来说你花了30分钟到地铁站，然而实际上你只花了20分钟。这儿就有了个差距。由于越接近公司，你的预测肯定越来越准确。所以可以认为后一次的预测更加的准确，因为后一次的预测里面有一些实际的成分（你实际花了20分钟从家到地铁站）。所以出门的时候预测要花50分钟就会更加准确。\n根据最优贝尔曼方程\n$Q_(s_t,a_t) = E_{S_{t+1}\\sim p(\\cdot|s_t,a_t)}[R_t+\\gamma \\max Q_(S_{t+1},A)|S_t=s_t,A_t=a_t]$\n其中$Q_*(s_t,a_t) = \\max_{a \\in A} Q(s_t,a)$。而 $p(\\cdot|s_t,a_t)$是确定$s_t$和$a_t$的情况下，可能得到的状态的状态的分布，并不是很重要的东西。按照蒙特卡洛的方法我们在t时刻的样本值\n$\\hat{q_t} \\approx r_t + \\max_{a \\in A} Q(s_{t+1},a)$\n翻译一下这个公式，可以看成是在$s_t$情况下$a_t$的一个采样，采样后得到$R_t$的样本值$r_t$，$S_{t+1}$也变成确定的$s_{t+1}$。而$\\hat{q_t}=Q_*(s_t,a_t)$\n我们可以基于$s_{t+1}$再做一次预测得到$\\hat{q}\u0026rsquo;=Q_*(s_{t+1},a_{t+1})$。如果我们有一个完美的DQN，那么就有$\\hat{q_t} \\approx r_t + \\gamma \\hat{q_{t+1}}$。\n类比上班的例子，就是让上班时间的两次预测的差值和实际的从家到地铁站的时间接近。 因此训练DQN的目标就是减少$J_w=\\frac{1}{2}[(\\hat{q_t} - \\gamma \\hat{q}\u0026rsquo;)- r_t ]^2$。注意$\\hat{q}\u0026rsquo;$是一个参考值，只是一个值，并不参与梯度的计算。 现在我们可以得到梯度:\n$\\triangledown_wJ = (\\hat{q_t} - r_t - \\gamma \\hat{q}\u0026rsquo;)\\triangledown_wQ(s_t,a_t)$\nreplay buffer # 在实际的DQN使用中，可以通过使用replay buffer来加快学习的效率。replay buffer主要的想法就是在获得关键的数据的时候，不要立即学习，而是保存起来到后面随机抽取一些四元组来学习。这样做有一些好处，首先抽取到的四元组是独立的，四元组之间不一定有什么关联。所以最好有一个很大的buffer，抽到的四元组之间才能更趋于独立。其次，这样可以保证每次都有足够的数据来训练，如果不用buffer，每次和环境交互以后只能得到一条数据，训练效果不好。\n每次当DQN看到一个状态$s_t$以后，就会计算action的概率，选择概率最大的$a_t$，然后和环境交互，环境的状态变成了$s_{t+1}$，并得到了奖励$r_t$,这时得到了一个四元组$(s_t,a_t,r_t,s_{t+1})$。我们把四元组保存在replay buffer中。随机从buffer中抽出一些四元组，按照DQN的方法来更新模型。\nprioritized replay buffer # 上节里面replay buffer中随机抽取四元组的方法可能并不能达到最好的效果，因为不同的四元组的状态是不同的。就比如超级玛丽中，第一关中的状态很容易出现，在多次的游戏中DQN会经常遇到这样的状态并让自己学习到在这样的状态下如何得到高分。但是后面关卡中或者是一些隐藏的关卡就很难遇到，更不要\n锚点 = 内容\nDQN的问题 # bootstraping\nPolicy Gradient # DQN优化策略 # actor critic # DDPG # ","date":"25 October 2021","permalink":"/posts/drl/","section":"Posts","summary":"基本模型 # 在机器学习的大类中，有一类学习过程需要和环境进行互动，在互动的过程中得到环境的反馈，而AI要做的事情就是通过学习来尽可能的得到更好的反馈。比如说让AI玩超级玛丽，在超级玛丽中，AI吃到金币得到好的反馈，碰到蘑菇怪🍄就会得到坏的反馈。而AI要做的就是学习如何看到一个画面的时候作出好的决定。其实过程和人类完游戏也差不多。","title":"Deep Reinforce Learning强化学习笔记"},{"content":"","date":"1 January 0001","permalink":"/authors/","section":"Authors","summary":"","title":"Authors"}]